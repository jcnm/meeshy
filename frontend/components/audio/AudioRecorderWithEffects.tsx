'use client';

import React, { useState, useRef, useEffect, useCallback, forwardRef, useImperativeHandle } from 'react';
import { createPortal } from 'react-dom';
import { Square, Trash2, Mic, Loader2, Radio } from 'lucide-react';
import { toast } from 'sonner';
import { useAudioEffects } from '@/hooks/use-audio-effects';
import { AudioEffectsCarousel } from '@/components/video-calls/AudioEffectsCarousel';
import type { AudioEffectType } from '@shared/types/video-call';

// Types
interface AudioMetadata {
  duration: number;
  codec: string;
  mimeType: string;
  bitrate?: number;
  sampleRate?: number;
}

interface AudioRecorderWithEffectsProps {
  onRecordingComplete: (audioBlob: Blob, duration: number, metadata?: AudioMetadata) => void;
  onRemove: () => void;
  maxDuration?: number;
  onRecordingStateChange?: (isRecording: boolean) => void;
  onStop?: () => void;
}

export interface AudioRecorderWithEffectsRef {
  stopRecording: () => void;
  isRecording: () => boolean;
}

const MAX_ALLOWED_DURATION = 600; // 10 minutes

// Codecs audio
const UNIVERSAL_CODEC_PRIORITIES = [
  'audio/mp4',
  'audio/webm;codecs=opus',
  'audio/webm',
  'audio/ogg;codecs=opus',
] as const;

const getBestAudioCodec = (): string => {
  for (const codec of UNIVERSAL_CODEC_PRIORITIES) {
    if (MediaRecorder.isTypeSupported(codec)) {
      return codec;
    }
  }
  throw new Error('No supported audio codec found');
};

export const AudioRecorderWithEffects = forwardRef<AudioRecorderWithEffectsRef, AudioRecorderWithEffectsProps>(({
  onRecordingComplete,
  onRemove,
  maxDuration = 600,
  onRecordingStateChange,
  onStop
}, ref) => {
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [permissionError, setPermissionError] = useState<string | null>(null);
  const [isInitializing, setIsInitializing] = useState(false);
  const [audioFormat, setAudioFormat] = useState<string>('WEBM');
  const [showEffectsPanel, setShowEffectsPanel] = useState(false);
  const [isMounted, setIsMounted] = useState(false);
  const [panelPosition, setPanelPosition] = useState({ top: 0, left: 0 });
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const buttonEffectsRef = useRef<HTMLButtonElement>(null);
  const chunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const animationFrameRef = useRef<number | null>(null);
  const selectedCodecRef = useRef<string>('');
  const requestDataIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const rawStreamRef = useRef<MediaStream | null>(null); // Stream du micro brut
  const [rawStream, setRawStream] = useState<MediaStream | null>(null); // State pour trigger useAudioEffects
  const processedAudioStreamRef = useRef<MediaStream | null>(null); // Ref pour acc√©der √† la derni√®re valeur

  const effectiveDuration = Math.min(maxDuration, MAX_ALLOWED_DURATION);

  // Initialiser useAudioEffects avec le stream brut (state, pas ref)
  const {
    outputStream: processedAudioStream,
    effectsState,
    toggleEffect,
    updateEffectParams,
    loadPreset,
    currentPreset,
    availableBackSounds,
    availablePresets,
  } = useAudioEffects({
    inputStream: rawStream,
  });

  // V√©rifier si des effets sont actifs
  const audioEffectsActive = Object.values(effectsState).some(effect => effect.enabled);

  // Formater le temps
  const formatTime = (milliseconds: number): string => {
    const totalSeconds = Math.floor(milliseconds / 1000);
    const ms = Math.floor((milliseconds % 1000) / 10);
    const mins = Math.floor(totalSeconds / 60);
    const secs = totalSeconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(2, '0')}`;
  };

  // Timer pr√©cis
  const updateTimer = useCallback(() => {
    if (!startTimeRef.current || !mediaRecorderRef.current || mediaRecorderRef.current.state !== 'recording') {
      return;
    }

    const elapsed = performance.now() - startTimeRef.current;
    setRecordingTime(elapsed);

    if (elapsed >= effectiveDuration * 1000) {
      stopRecording();
      return;
    }

    animationFrameRef.current = requestAnimationFrame(updateTimer);
  }, [effectiveDuration]);


  // Arr√™ter l'enregistrement
  const stopRecording = useCallback(() => {
    if (onStop) {
      onStop();
    }

    if (requestDataIntervalRef.current) {
      clearInterval(requestDataIntervalRef.current);
      requestDataIntervalRef.current = null;
    }

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    startTimeRef.current = 0;

    // Arr√™ter le stream brut
    if (rawStreamRef.current) {
      rawStreamRef.current.getTracks().forEach(track => track.stop());
      rawStreamRef.current = null;
    }
    setRawStream(null); // Reset le state

    // Arr√™ter le media recorder
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    setIsRecording(false);

    if (onRecordingStateChange) {
      onRecordingStateChange(false);
    }
  }, [onRecordingStateChange, onStop]);

  // D√©marrer l'enregistrement
  const startRecording = useCallback(async () => {
    setPermissionError(null);
    setIsInitializing(true);

    try {
      if (!window.isSecureContext) {
        toast.error('Audio recording requires HTTPS.');
        setPermissionError('HTTPS required');
        setIsInitializing(false);
        return;
      }

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast.error('Your browser does not support audio recording.');
        setPermissionError('Browser not supported');
        setIsInitializing(false);
        return;
      }

      const mimeType = getBestAudioCodec();
      selectedCodecRef.current = mimeType;

      // Obtenir le stream brut du microphone
      const newRawStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false, // D√©sactiver pour laisser useAudioEffects g√©rer
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 48000,
          channelCount: 2, // St√©r√©o pour une meilleure qualit√© audio
        }
      });

      rawStreamRef.current = newRawStream;
      setRawStream(newRawStream); // Trigger useAudioEffects

      // Attendre TOUJOURS que useAudioEffects initialise le stream de sortie
      // Cela permet d'activer les effets PENDANT l'enregistrement
      console.log('üé≠ [AudioRecorder] Waiting for processedAudioStream to be ready...');

      const maxWaitTime = 3000; // 3 secondes maximum
      const checkInterval = 100; // V√©rifier toutes les 100ms
      const startWait = Date.now();

      let streamToRecord = newRawStream;

      while (Date.now() - startWait < maxWaitTime) {
        // V√©rifier la ref pour avoir la valeur la plus r√©cente
        const currentProcessedStream = processedAudioStreamRef.current;

        // V√©rifier si processedAudioStream existe et a des audio tracks
        if (currentProcessedStream && currentProcessedStream.getAudioTracks().length > 0) {
          console.log('‚úÖ [AudioRecorder] processedAudioStream is ready!', {
            tracks: currentProcessedStream.getAudioTracks().length,
            waitTime: Date.now() - startWait
          });
          streamToRecord = currentProcessedStream;
          break;
        }

        // Attendre avant de v√©rifier √† nouveau
        await new Promise(resolve => setTimeout(resolve, checkInterval));
      }

      // Si apr√®s le timeout le stream n'est pas pr√™t, avertir et utiliser le stream brut
      if (streamToRecord === newRawStream) {
        const currentProcessedStream = processedAudioStreamRef.current;
        console.warn('‚ö†Ô∏è [AudioRecorder] processedAudioStream not ready after 3s, using raw stream', {
          processedAudioStreamExists: !!currentProcessedStream,
          audioTracksCount: currentProcessedStream?.getAudioTracks().length || 0
        });
        toast.warning('Effets audio non disponibles - utilisation du micro direct');
      }

      const mediaRecorder = new MediaRecorder(streamToRecord, {
        mimeType,
        audioBitsPerSecond: 128000,
        bitsPerSecond: 128000
      });

      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: mimeType });

        // Arr√™ter tous les tracks du stream brut
        newRawStream.getTracks().forEach(track => track.stop());
        setRawStream(null); // Reset le state

        const format = mimeType.includes('webm') ? 'WEBM' :
                      mimeType.includes('mp4') ? 'MP4' :
                      mimeType.includes('ogg') ? 'OGG' : 'AUDIO';
        setAudioFormat(format);

        const metadata: AudioMetadata = {
          duration: recordingTime / 1000,
          codec: format,
          mimeType: mimeType,
        };

        onRecordingComplete(blob, metadata.duration, metadata);
      };

      mediaRecorder.start();

      // requestData() manuel
      requestDataIntervalRef.current = setInterval(() => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.requestData();
        }
      }, 1000);

      setIsRecording(true);
      setIsInitializing(false);
      setRecordingTime(0);

      if (onRecordingStateChange) {
        onRecordingStateChange(true);
      }

      startTimeRef.current = performance.now();
      animationFrameRef.current = requestAnimationFrame(updateTimer);

    } catch (error: any) {
      setIsInitializing(false);

      if (error instanceof DOMException) {
        if (error.name === 'NotAllowedError') {
          setPermissionError('Microphone access denied');
          toast.error('Acc√®s au microphone refus√©.');
        } else if (error.name === 'NotFoundError') {
          setPermissionError('No microphone found');
          toast.error('Aucun microphone d√©tect√©.');
        } else {
          setPermissionError('Microphone error');
          toast.error('Erreur microphone.');
        }
      } else {
        toast.error('Impossible d\'acc√©der au microphone.');
        setPermissionError('Recording error');
      }
    }
  }, [effectiveDuration, onRecordingComplete, updateTimer, onRecordingStateChange]);

  // Exposer les m√©thodes via ref
  useImperativeHandle(ref, () => ({
    stopRecording,
    isRecording: () => isRecording
  }), [stopRecording, isRecording]);

  // D√©tecter le montage du composant pour le portail
  useEffect(() => {
    setIsMounted(true);
    return () => setIsMounted(false);
  }, []);

  // Mettre √† jour la ref processedAudioStream pour y acc√©der dans les closures
  useEffect(() => {
    processedAudioStreamRef.current = processedAudioStream;
  }, [processedAudioStream]);

  // Calculer et mettre √† jour la position du panneau
  const updatePanelPosition = useCallback(() => {
    if (!buttonEffectsRef.current) return;

    const rect = buttonEffectsRef.current.getBoundingClientRect();
    setPanelPosition({
      top: rect.top - 10,
      left: rect.left,
    });
  }, []);

  // Mettre √† jour la position lors de l'ouverture du panneau et lors du scroll/resize
  useEffect(() => {
    if (!showEffectsPanel) return;

    // Mettre √† jour la position imm√©diatement
    updatePanelPosition();

    // Puis lors du scroll/resize
    window.addEventListener('scroll', updatePanelPosition, true);
    window.addEventListener('resize', updatePanelPosition);

    return () => {
      window.removeEventListener('scroll', updatePanelPosition, true);
      window.removeEventListener('resize', updatePanelPosition);
    };
  }, [showEffectsPanel, updatePanelPosition]);

  // Cleanup
  useEffect(() => {
    return () => {
      if (requestDataIntervalRef.current) {
        clearInterval(requestDataIntervalRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }
      if (rawStreamRef.current) {
        rawStreamRef.current.getTracks().forEach(track => track.stop());
        rawStreamRef.current = null;
      }
      setRawStream(null);
    };
  }, []);

  // √âtat: Initialisation
  if (isInitializing) {
    return (
      <div className="relative group pt-2 pb-1">
        <div className="relative flex flex-col items-center justify-center w-full h-24 bg-gradient-to-br from-blue-50 to-indigo-50 dark:from-blue-900/30 dark:to-indigo-900/30 border-2 border-blue-400 dark:border-blue-500 rounded-lg">
          <Loader2 className="w-6 h-6 text-blue-600 dark:text-blue-400 animate-spin" />
          <div className="text-xs text-blue-600 dark:text-blue-400 mt-1">
            Initialisation...
          </div>
        </div>
        <button
          onClick={onRemove}
          className="absolute -top-1 -right-1 w-5 h-5 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center shadow-md z-10"
        >
          <Trash2 className="w-5 h-5" />
        </button>
      </div>
    );
  }

  // √âtat: Erreur
  if (permissionError) {
    return (
      <div className="relative group pt-2 pb-1">
        <div className="relative flex flex-col items-center justify-center w-full h-24 bg-red-50 dark:bg-red-900/20 border-2 border-red-400 dark:border-red-500 rounded-lg">
          <Mic className="w-6 h-6 text-red-600 dark:text-red-400 mb-1" />
          <div className="text-xs text-red-600 dark:text-red-400 text-center px-2">
            {permissionError}
          </div>
        </div>
        <button
          onClick={onRemove}
          className="absolute -top-1 -right-1 w-5 h-5 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center shadow-md z-10"
        >
          <Trash2 className="w-5 h-5" />
        </button>
      </div>
    );
  }

  // √âtat: Pr√™t √† enregistrer OU En cours d'enregistrement
  return (
    <>
      {/* Panneau des effets audio - Portail pour afficher au-dessus de tout */}
      {isMounted && showEffectsPanel && createPortal(
        <>
          {/* Overlay pour fermer au clic √† l'ext√©rieur */}
          <div
            className="fixed inset-0 bg-black/50 z-[9998]"
            onClick={() => setShowEffectsPanel(false)}
          />

          {/* Panneau centr√© sur mobile, positionn√© pr√®s du bouton sur desktop */}
          <div
            className="fixed z-[9999] md:absolute w-[95vw] md:w-[800px]"
            style={{
              // Mobile: centr√© horizontalement et verticalement
              left: '50%',
              top: '50%',
              transform: 'translate(-50%, -50%)',
              maxWidth: '95vw',
              maxHeight: '85vh',
            }}
          >
            <AudioEffectsCarousel
              effectsState={effectsState}
              onToggleEffect={toggleEffect}
              onUpdateParams={updateEffectParams}
              onLoadPreset={loadPreset}
              currentPreset={currentPreset}
              availablePresets={availablePresets}
              availableBackSounds={availableBackSounds}
              onClose={() => setShowEffectsPanel(false)}
            />
          </div>
        </>,
        document.body
      )}

      <div className="relative group pt-2 pb-1">
        {/* Composant principal */}
      <div className={`relative flex flex-row items-center justify-between gap-2 w-full h-16 rounded-lg px-2 py-1.5 border-2 ${
        isRecording
          ? 'bg-gradient-to-br from-red-50 to-orange-50 dark:from-red-900/30 dark:to-orange-900/30 border-red-400 dark:border-red-500'
          : 'bg-gradient-to-br from-gray-50 to-gray-100 dark:from-gray-800/30 dark:to-gray-900/30 border-gray-300 dark:border-gray-600'
      }`}>
        {/* Gauche: Bouton effets audio */}
        <button
          ref={buttonEffectsRef}
          onClick={() => setShowEffectsPanel(!showEffectsPanel)}
          onTouchStart={() => setShowEffectsPanel(!showEffectsPanel)}
          className={`relative flex-shrink-0 w-10 h-10 rounded-full flex items-center justify-center transition-all ${
            audioEffectsActive
              ? 'bg-gradient-to-br from-purple-500 to-pink-500 shadow-lg shadow-purple-500/50'
              : 'bg-gradient-to-br from-gray-300 to-gray-400 dark:from-gray-600 dark:to-gray-700'
          } hover:scale-105 active:scale-95`}
          title="Effets audio"
        >
          <span className="text-xl">üé≠</span>
          {audioEffectsActive && (
            <div className="absolute -top-1 -right-1 w-2.5 h-2.5 bg-green-500 rounded-full border-2 border-white" />
          )}
        </button>

        {/* Centre: Timer centr√© verticalement avec barre de progression */}
        <div className="flex flex-col items-center justify-center flex-1 gap-1.5">
          <div className={`text-2xl font-bold font-mono ${
            isRecording ? 'text-red-600 dark:text-red-400' : 'text-gray-600 dark:text-gray-400'
          }`}>
            {formatTime(recordingTime)}
          </div>

          {/* Barre de progression (visible uniquement en enregistrement) */}
          {isRecording && (
            <div className="w-full max-w-[200px] h-1.5 bg-gray-200 dark:bg-gray-700 rounded-full overflow-hidden">
              <div
                className="h-full bg-gradient-to-r from-red-500 to-orange-500 transition-all duration-300 ease-linear"
                style={{
                  width: `${Math.min((recordingTime / (effectiveDuration * 1000)) * 100, 100)}%`
                }}
              />
            </div>
          )}
        </div>

        {/* Droite: Bouton Start/Stop */}
        {!isRecording ? (
          <button
            onClick={startRecording}
            onTouchStart={(e) => {
              e.preventDefault();
              startRecording();
            }}
            className="flex-shrink-0 w-10 h-10 bg-blue-500 hover:bg-blue-600 active:bg-blue-700 rounded-full flex items-center justify-center transition-all shadow-lg active:scale-95"
            title="D√©marrer l'enregistrement"
          >
            <Radio className="w-5 h-5 text-white" />
          </button>
        ) : (
          <button
            onClick={stopRecording}
            onTouchStart={(e) => {
              e.preventDefault();
              stopRecording();
            }}
            className="flex-shrink-0 w-10 h-10 bg-red-500 hover:bg-red-600 active:bg-red-700 rounded-full flex items-center justify-center transition-all shadow-lg active:scale-95"
            title="Arr√™ter l'enregistrement"
          >
            <Square className="w-4 h-4 fill-white stroke-white" />
          </button>
        )}
      </div>

      {/* Badge dur√©e max */}
      <div className="absolute bottom-0 left-1/2 -translate-x-1/2 bg-gray-700 text-white text-[8px] px-2 py-0.5 rounded-full whitespace-nowrap shadow-sm">
        Max {Math.floor(effectiveDuration / 60)}min
      </div>

      {/* Bouton supprimer */}
      {!isRecording && (
        <button
          onClick={onRemove}
          className="absolute -top-1 -right-1 w-5 h-5 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center opacity-0 group-hover:opacity-100 transition-opacity shadow-md z-10"
        >
          <Trash2 className="w-5 h-5" />
        </button>
      )}
      </div>
    </>
  );
});

AudioRecorderWithEffects.displayName = 'AudioRecorderWithEffects';

"""
Service de cache optimis√© pour les traductions
Utilise Redis + cache local pour performance maximale
"""

import asyncio
import hashlib
import json
import logging
import time
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass

try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

from config.settings import get_settings

logger = logging.getLogger(__name__)

@dataclass
class CacheEntry:
    """Entr√©e de cache avec m√©tadonn√©es"""
    value: str
    created_at: float
    hits: int = 0
    source_lang: str = ""
    target_lang: str = ""
    model_type: str = "basic"

class CacheService:
    """Service de cache multi-niveau pour les traductions"""
    
    def __init__(self):
        self.settings = get_settings()
        self.redis_client: Optional[redis.Redis] = None
        self.local_cache: Dict[str, CacheEntry] = {}
        self.stats = {
            'redis_hits': 0,
            'local_hits': 0,
            'misses': 0,
            'total_requests': 0,
            'redis_errors': 0
        }
        self.is_initialized = False
    
    async def initialize(self):
        """Initialise le service de cache"""
        try:
            if REDIS_AVAILABLE:
                logger.info("üîå Connexion √† Redis...")
                self.redis_client = redis.from_url(
                    self.settings.redis_url,
                    encoding='utf-8',
                    decode_responses=True,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
                
                # Test de connexion
                await self.redis_client.ping()
                logger.info("‚úÖ Redis connect√© avec succ√®s")
            else:
                logger.warning("‚ö†Ô∏è Redis non disponible, utilisation du cache local uniquement")
            
            self.is_initialized = True
            logger.info("üì¶ Service de cache initialis√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation du cache: {e}")
            logger.warning("üîÑ Basculement vers le cache local uniquement")
            self.redis_client = None
            self.is_initialized = True
    
    def _generate_cache_key(self, text: str, source_lang: str, target_lang: str, model_type: str = "basic") -> str:
        """G√©n√®re une cl√© de cache unique"""
        # Normaliser le texte pour am√©liorer les hits de cache
        normalized_text = text.strip().lower()
        
        # Cr√©er la cl√© avec hash pour √©viter les cl√©s trop longues
        key_data = f"{normalized_text}:{source_lang}:{target_lang}:{model_type}"
        key_hash = hashlib.sha256(key_data.encode()).hexdigest()[:16]
        
        return f"meeshy:translate:{source_lang}:{target_lang}:{model_type}:{key_hash}"
    
    async def get_translation(self, text: str, source_lang: str, target_lang: str, model_type: str = "basic") -> Optional[Dict[str, Any]]:
        """R√©cup√®re une traduction du cache"""
        if not self.is_initialized:
            return None
        
        cache_key = self._generate_cache_key(text, source_lang, target_lang, model_type)
        self.stats['total_requests'] += 1
        
        # 1. V√©rifier le cache local d'abord (plus rapide)
        if cache_key in self.local_cache:
            entry = self.local_cache[cache_key]
            
            # V√©rifier l'expiration
            if time.time() - entry.created_at < self.settings.translation_cache_ttl:
                entry.hits += 1
                self.stats['local_hits'] += 1
                
                logger.debug(f"üí® Cache local HIT: {cache_key}")
                return {
                    'translated_text': entry.value,
                    'from_cache': True,
                    'cache_source': 'local',
                    'cache_key': cache_key,
                    'hits': entry.hits
                }
            else:
                # Entr√©e expir√©e, la supprimer
                del self.local_cache[cache_key]
        
        # 2. V√©rifier Redis si disponible
        if self.redis_client:
            try:
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    data = json.loads(cached_data)
                    self.stats['redis_hits'] += 1
                    
                    # Sauvegarder dans le cache local pour les prochaines requ√™tes
                    self.local_cache[cache_key] = CacheEntry(
                        value=data['translated_text'],
                        created_at=time.time(),
                        hits=data.get('hits', 0) + 1,
                        source_lang=source_lang,
                        target_lang=target_lang,
                        model_type=model_type
                    )
                    
                    logger.debug(f"üî• Cache Redis HIT: {cache_key}")
                    return {
                        'translated_text': data['translated_text'],
                        'from_cache': True,
                        'cache_source': 'redis',
                        'cache_key': cache_key,
                        'hits': data.get('hits', 0) + 1
                    }
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur Redis GET: {e}")
                self.stats['redis_errors'] += 1
        
        # 3. Aucun cache trouv√©
        self.stats['misses'] += 1
        logger.debug(f"‚ùå Cache MISS: {cache_key}")
        return None
    
    async def set_translation(self, text: str, source_lang: str, target_lang: str, translated_text: str, model_type: str = "basic", metadata: Optional[Dict] = None) -> bool:
        """Sauvegarde une traduction dans le cache"""
        if not self.is_initialized:
            return False
        
        cache_key = self._generate_cache_key(text, source_lang, target_lang, model_type)
        current_time = time.time()
        
        # Donn√©es √† cacher
        cache_data = {
            'translated_text': translated_text,
            'source_lang': source_lang,
            'target_lang': target_lang,
            'model_type': model_type,
            'created_at': current_time,
            'hits': 0
        }
        
        if metadata:
            cache_data.update(metadata)
        
        try:
            # 1. Sauvegarder dans le cache local
            self.local_cache[cache_key] = CacheEntry(
                value=translated_text,
                created_at=current_time,
                source_lang=source_lang,
                target_lang=target_lang,
                model_type=model_type
            )
            
            # Limiter la taille du cache local
            if len(self.local_cache) > self.settings.cache_max_entries:
                await self._cleanup_local_cache()
            
            # 2. Sauvegarder dans Redis si disponible
            if self.redis_client:
                await self.redis_client.setex(
                    cache_key,
                    self.settings.translation_cache_ttl,
                    json.dumps(cache_data)
                )
            
            logger.debug(f"‚úÖ Cache SET: {cache_key}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde en cache: {e}")
            if self.redis_client:
                self.stats['redis_errors'] += 1
            return False
    
    async def _cleanup_local_cache(self):
        """Nettoie le cache local en gardant les entr√©es les plus r√©centes et utilis√©es"""
        if len(self.local_cache) <= self.settings.cache_max_entries:
            return
        
        # Trier par hits (plus utilis√©es) et date (plus r√©centes)
        sorted_entries = sorted(
            self.local_cache.items(),
            key=lambda x: (x[1].hits, x[1].created_at),
            reverse=True
        )
        
        # Garder seulement les 80% meilleures entr√©es
        keep_count = int(self.settings.cache_max_entries * 0.8)
        entries_to_keep = dict(sorted_entries[:keep_count])
        
        removed_count = len(self.local_cache) - len(entries_to_keep)
        self.local_cache = entries_to_keep
        
        logger.info(f"üßπ Cache local nettoy√©: {removed_count} entr√©es supprim√©es")
    
    async def clear_cache(self, pattern: Optional[str] = None):
        """Vide le cache (local et Redis)"""
        # Vider le cache local
        if pattern:
            keys_to_remove = [k for k in self.local_cache.keys() if pattern in k]
            for key in keys_to_remove:
                del self.local_cache[key]
            logger.info(f"üßπ Cache local vid√© pour le pattern: {pattern}")
        else:
            self.local_cache.clear()
            logger.info("üßπ Cache local enti√®rement vid√©")
        
        # Vider Redis si disponible
        if self.redis_client:
            try:
                if pattern:
                    keys = await self.redis_client.keys(f"meeshy:translate:*{pattern}*")
                    if keys:
                        await self.redis_client.delete(*keys)
                        logger.info(f"üßπ Cache Redis vid√© pour le pattern: {pattern} ({len(keys)} cl√©s)")
                else:
                    keys = await self.redis_client.keys("meeshy:translate:*")
                    if keys:
                        await self.redis_client.delete(*keys)
                        logger.info(f"üßπ Cache Redis enti√®rement vid√© ({len(keys)} cl√©s)")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du vidage Redis: {e}")
                self.stats['redis_errors'] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache"""
        total_requests = self.stats['total_requests']
        if total_requests > 0:
            hit_rate = (self.stats['redis_hits'] + self.stats['local_hits']) / total_requests * 100
        else:
            hit_rate = 0
        
        return {
            **self.stats,
            'hit_rate_percent': round(hit_rate, 2),
            'local_cache_size': len(self.local_cache),
            'redis_available': self.redis_client is not None,
            'cache_initialized': self.is_initialized
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """V√©rifie la sant√© du service de cache"""
        health = {
            'local_cache': True,
            'redis': False,
            'redis_latency_ms': None
        }
        
        if self.redis_client:
            try:
                start_time = time.time()
                await self.redis_client.ping()
                latency = (time.time() - start_time) * 1000
                
                health['redis'] = True
                health['redis_latency_ms'] = round(latency, 2)
            except Exception as e:
                logger.error(f"‚ùå Health check Redis failed: {e}")
        
        return health
    
    async def close(self):
        """Ferme les connexions du service de cache"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("‚úÖ Connexion Redis ferm√©e")
        
        self.local_cache.clear()
        logger.info("‚úÖ Service de cache ferm√©")

"""
Module de segmentation de texte pour traduction structurÃ©e
PrÃ©serve les paragraphes, sauts de ligne et emojis dans les traductions
"""

import re
from typing import List, Tuple, Dict
import logging

logger = logging.getLogger(__name__)

# Pattern ULTRA-ROBUSTE pour tous les types d'emojis
# Inclut tous les ranges Unicode emoji + modificateurs + ZWJ sequences
EMOJI_PATTERN = re.compile(
    "(?:"
    # Emojis avec modificateurs de peau (skin tone) et ZWJ
    "[\U0001F3FB-\U0001F3FF]|"  # Modificateurs de peau
    "\U0000200D|"  # Zero Width Joiner (ZWJ)
    "\U0000FE0F|"  # Variation Selector-16 (prÃ©sentation emoji)
    "\U0000FE0E|"  # Variation Selector-15 (prÃ©sentation texte)
    # Emojis de base
    "[\U0001F600-\U0001F64F]|"  # Emoticons
    "[\U0001F300-\U0001F5FF]|"  # Symbols & Pictographs
    "[\U0001F680-\U0001F6FF]|"  # Transport & Map Symbols
    "[\U0001F700-\U0001F77F]|"  # Alchemical Symbols
    "[\U0001F780-\U0001F7FF]|"  # Geometric Shapes Extended
    "[\U0001F800-\U0001F8FF]|"  # Supplemental Arrows-C
    "[\U0001F900-\U0001F9FF]|"  # Supplemental Symbols and Pictographs
    "[\U0001FA00-\U0001FA6F]|"  # Chess Symbols
    "[\U0001FA70-\U0001FAFF]|"  # Symbols and Pictographs Extended-A
    "[\U00002702-\U000027B0]|"  # Dingbats
    "[\U000024C2-\U0001F251]|"  # Enclosed characters
    "[\U0001F1E0-\U0001F1FF]|"  # Regional Indicator Symbols (flags)
    "[\U00002600-\U000026FF]|"  # Miscellaneous Symbols
    "[\U00002700-\U000027BF]|"  # Dingbats
    "[\U0001F900-\U0001F9FF]|"  # Supplemental Symbols
    "[\U0001FA00-\U0001FAFF]|"  # Extended Pictographs
    # Symboles additionnels souvent utilisÃ©s comme emojis
    "[\u2600-\u26FF]|"  # Miscellaneous Symbols
    "[\u2700-\u27BF]|"  # Dingbats
    "[\u2B50]|"  # Star
    "[\u2934-\u2935]|"  # Arrows
    "[\u3030]|"  # Wavy dash
    "[\u303D]|"  # Part alternation mark
    "[\u3297]|"  # Circled Ideograph Congratulation
    "[\u3299]|"  # Circled Ideograph Secret
    # Keycap sequences
    "[\u0023\u002A\u0030-\u0039]\uFE0F?\u20E3|"  # Keycaps
    # Copyright, registered, trademark
    "[\u00A9\u00AE\u203C\u2049\u2122\u2139]|"
    # Arrows
    "[\u2194-\u2199\u21A9-\u21AA]|"
    # Checkmarks, crosses
    "[\u231A-\u231B\u2328\u23CF\u23E9-\u23F3\u23F8-\u23FA\u24C2]|"
    # Geometric shapes
    "[\u25AA-\u25AB\u25B6\u25C0\u25FB-\u25FE]|"
    # Additional symbols
    "[\u2934-\u2935\u2B05-\u2B07\u2B1B-\u2B1C\u2B50\u2B55]|"
    # Emojis rÃ©cents (Unicode 13.0+)
    "[\U0001F90C-\U0001F971]|"  # Nouveaux emojis
    "[\U0001F973-\U0001F976]|"
    "[\U0001F97A-\U0001F9A2]|"
    "[\U0001F9A5-\U0001F9AA]|"
    "[\U0001F9AE-\U0001F9CA]|"
    "[\U0001F9CD-\U0001F9FF]|"
    "[\U0001FA70-\U0001FA74]|"
    "[\U0001FA78-\U0001FA7A]|"
    "[\U0001FA80-\U0001FA86]|"
    "[\U0001FA90-\U0001FAA8]|"
    "[\U0001FAB0-\U0001FAB6]|"
    "[\U0001FAC0-\U0001FAC2]|"
    "[\U0001FAD0-\U0001FAD6]"
    ")+",
    flags=re.UNICODE
)

# Marqueur spÃ©cial pour les emojis - Format ULTRA-ROBUSTE
# Format: ğŸ”¹EMOJI_XğŸ”¹ oÃ¹ X est l'index
# Utilisation de marqueurs Unicode spÃ©ciaux qui ne sont JAMAIS traduits par les modÃ¨les ML
# Le caractÃ¨re ğŸ”¹ est rare et facilement dÃ©tectable, pas confondu avec du texte
# AMÃ‰LIORATION: Plus rÃ©sistant que XML/HTML aux modifications du modÃ¨le ML
EMOJI_PLACEHOLDER = "ğŸ”¹EMOJI_{index}ğŸ”¹"

# Marqueur pour les sauts de ligne (pour prÃ©servation explicite)
NEWLINE_MARKER = "__NL__"

class TextSegmenter:
    """GÃ¨re la segmentation de texte pour traduction avec prÃ©servation de structure"""

    def __init__(self, max_segment_length: int = 100):
        """
        Args:
            max_segment_length: Nombre maximum de caractÃ¨res par segment (en dessous de max_length du modÃ¨le)
        """
        self.max_segment_length = max_segment_length

    def extract_emojis(self, text: str) -> Tuple[str, Dict[int, str]]:
        """
        Extrait TOUS les emojis (y compris complexes avec ZWJ, modificateurs de peau, etc.)
        et les remplace par des marqueurs robustes

        Returns:
            (texte_sans_emojis, mapping_index_vers_emoji)
        """
        emojis_map = {}
        emoji_index = 0

        # Log du texte avant extraction
        logger.debug(f"[SEGMENTER] Texte avant extraction emojis: {repr(text[:100])}")

        def replacer(match):
            nonlocal emoji_index
            emoji = match.group(0)
            # Log chaque emoji extrait avec son code Unicode pour debug
            emoji_codes = ' '.join([f'U+{ord(c):04X}' for c in emoji])
            logger.debug(f"[SEGMENTER] Emoji {emoji_index} extrait: {emoji} ({emoji_codes})")

            emojis_map[emoji_index] = emoji
            placeholder = EMOJI_PLACEHOLDER.format(index=emoji_index)
            emoji_index += 1
            return placeholder

        text_without_emojis = EMOJI_PATTERN.sub(replacer, text)

        if emojis_map:
            logger.info(f"[SEGMENTER] âœ… Extracted {len(emojis_map)} emojis: {list(emojis_map.values())}")
        else:
            logger.debug(f"[SEGMENTER] â„¹ï¸  No emojis found in text")

        # VÃ©rification: s'assurer qu'aucun emoji n'est restÃ©
        remaining_emojis = EMOJI_PATTERN.findall(text_without_emojis)
        if remaining_emojis:
            logger.warning(f"[SEGMENTER] âš ï¸  {len(remaining_emojis)} emojis NOT extracted: {remaining_emojis}")

        return text_without_emojis, emojis_map

    def restore_emojis(self, text: str, emojis_map: Dict[int, str]) -> str:
        """
        Restaure TOUS les emojis Ã  partir des marqueurs

        PRINCIPE SIMPLE:
        - Remplacer chaque placeholder par son emoji
        - NE PAS toucher aux emojis (mÃªme s'ils sont collÃ©s aux mots)
        - FOCUS: PrÃ©servation de la structure verticale
        """
        result = text
        restored_count = 0
        not_found_placeholders = []

        # Restaurer les placeholders
        for index, emoji in emojis_map.items():
            placeholder = EMOJI_PLACEHOLDER.format(index=index)

            # VÃ©rifier si le placeholder est prÃ©sent
            if placeholder in result:
                result = result.replace(placeholder, emoji)
                restored_count += 1
                logger.debug(f"[SEGMENTER] Emoji {index} restaurÃ©: {emoji}")
            else:
                not_found_placeholders.append((index, emoji, placeholder))
                logger.warning(f"[SEGMENTER] âš ï¸  Placeholder {placeholder} NOT FOUND for emoji {emoji}")

        # Log final
        if emojis_map:
            logger.info(f"[SEGMENTER] âœ… Restored {restored_count}/{len(emojis_map)} emojis")

        if not_found_placeholders:
            logger.error(f"[SEGMENTER] âŒ {len(not_found_placeholders)} emojis NOT restored:")
            for idx, emoji, placeholder in not_found_placeholders:
                logger.error(f"    - Index {idx}: {emoji} (placeholder: {placeholder})")

        # VÃ©rification finale: s'assurer qu'il ne reste aucun placeholder
        remaining_placeholders = re.findall(r'ğŸ”¹EMOJI_\d+ğŸ”¹', result)
        if remaining_placeholders:
            logger.error(f"[SEGMENTER] âŒ {len(remaining_placeholders)} placeholders NOT replaced: {remaining_placeholders}")

        return result

    def is_list_item(self, line: str) -> bool:
        """
        DÃ©tecte si une ligne est un Ã©lÃ©ment de liste

        Patterns reconnus:
        - Tirets: -, â€¢, *, â†’
        - NumÃ©ros: 1., 2., 3., etc.
        - Lettres: a), b), c)
        - Lettres romaines: I), II), III), etc.
        """
        stripped = line.strip()
        if not stripped:
            return False

        # Pattern pour listes Ã  puces
        bullet_pattern = r'^[+-â€¢*â†’]\s+'
        # Pattern pour listes numÃ©rotÃ©es (1., 2., etc.)
        numbered_pattern = r'^\d+\.\s+'
        # Pattern pour listes avec lettres (a), b), etc.)
        lettered_pattern = r'^[a-z]\)\s+'
        # Pattern pour listes avec lettres (I), II), etc.)
        roman_lettered_pattern = r'^[IVXLCDM]+\)\s+'

        return (re.match(bullet_pattern, stripped) is not None or
                re.match(numbered_pattern, stripped) is not None or
                re.match(lettered_pattern, stripped) is not None or
                re.match(roman_lettered_pattern, stripped) is not None)

    def segment_by_sentences_and_lines(self, text: str) -> List[Tuple[str, str]]:
        """
        ALGORITHME SIMPLIFIÃ‰ : DÃ©couper par retour Ã  la ligne et mÃ©moriser le type de sÃ©parateur

        Logique simple :
        1. Split par \n et capturer les sÃ©parateurs
        2. Chaque ligne devient un segment Ã  traduire
        3. DÃ©tecter les blocs de code (``` ... ```) et les marquer comme non traduisibles
        4. MÃ©moriser si aprÃ¨s chaque ligne il faut reconstruire avec 1 ou plusieurs \n

        Returns:
            Liste de tuples (segment, type)
            - segment: texte de la ligne
            - type: 'line' (ligne normale), 'separator' (sÃ©parateur \n), 'code' (ligne de code non traduisible)
        """
        segments = []

        # Split avec capture pour prÃ©server les \n
        # Pattern: Split sur \n mais capturer les \n consÃ©cutifs
        parts = re.split(r'(\n+)', text)

        # Ã‰tat pour dÃ©tecter les blocs de code
        in_code_block = False

        for i, part in enumerate(parts):
            if not part:
                continue

            # Les indices impairs sont les sÃ©parateurs (\n, \n\n, \n\n\n, etc.)
            if i % 2 == 1:
                # C'est un sÃ©parateur - mÃ©moriser combien de \n
                segments.append((part, 'separator'))
            else:
                # C'est une ligne de texte (peut Ãªtre vide)
                # IMPORTANT: Utiliser rstrip() pour prÃ©server l'indentation Ã  gauche (pour le code)
                if part.strip():  # Seulement si la ligne contient du texte
                    stripped = part.strip()

                    # DÃ©tecter les dÃ©limiteurs de blocs de code (```)
                    if stripped.startswith('```'):
                        in_code_block = not in_code_block
                        # Les lignes ``` elles-mÃªmes sont du code (non traduisibles)
                        segments.append((part.rstrip(), 'code'))
                    elif in_code_block:
                        # On est dans un bloc de code - ne pas traduire
                        segments.append((part.rstrip(), 'code'))
                    else:
                        # Ligne normale - Ã  traduire
                        segments.append((part.rstrip(), 'line'))
                elif part:  # Ligne avec uniquement des espaces
                    segments.append(('', 'empty_line'))

        logger.debug(f"[SEGMENTER] Segmented into {len(segments)} parts by line breaks")
        return segments

    def segment_by_sentences(self, text: str) -> List[str]:
        """
        Segmente un paragraphe en phrases si trop long
        PrÃ©serve les sauts de ligne simples
        """
        # Si le texte est court, retourner tel quel
        if len(text) <= self.max_segment_length:
            return [text]

        # Remplacer temporairement les sauts de ligne simples
        text_with_markers = text.replace('\n', NEWLINE_MARKER)

        # DÃ©couper par phrases (., !, ?, ;)
        sentences = re.split(r'([.!?;]+\s+)', text_with_markers)

        # Regrouper les phrases avec leur ponctuation
        segments = []
        current_segment = ""

        for i, part in enumerate(sentences):
            # Les indices pairs sont les phrases, impairs sont les sÃ©parateurs
            if i % 2 == 0:
                current_segment += part
            else:
                current_segment += part

                # Si le segment est assez long, l'ajouter
                if len(current_segment) >= self.max_segment_length * 0.7:
                    segments.append(current_segment.strip())
                    current_segment = ""

        # Ajouter le dernier segment s'il existe
        if current_segment.strip():
            segments.append(current_segment.strip())

        # Restaurer les sauts de ligne
        segments = [s.replace(NEWLINE_MARKER, '\n') for s in segments]

        logger.debug(f"[SEGMENTER] Split long paragraph into {len(segments)} sentences")
        return segments if segments else [text]

    def segment_text(self, text: str) -> Tuple[List[Dict], Dict[int, str]]:
        """
        Segmente le texte intelligemment en prÃ©servant la structure

        Returns:
            (liste_segments, mapping_emojis)
            Chaque segment est un dict: {
                'text': str,
                'type': 'sentence' | 'list_item' | 'paragraph_break',
                'index': int
            }
        """
        # 1. Extraire les emojis
        text_no_emojis, emojis_map = self.extract_emojis(text)

        # 2. Segmenter intelligemment (phrases + listes)
        parts = self.segment_by_sentences_and_lines(text_no_emojis)

        # 3. CrÃ©er les segments
        segments = []
        segment_index = 0

        for part_text, part_type in parts:
            segments.append({
                'text': part_text,
                'type': part_type,
                'index': segment_index
            })
            segment_index += 1

        logger.info(f"[SEGMENTER] Text segmented into {len(segments)} parts ({len([s for s in segments if s['type'] == 'line'])} translatable lines) with {len(emojis_map)} emojis")
        return segments, emojis_map

    def reassemble_text(self, translated_segments: List[Dict], emojis_map: Dict[int, str]) -> str:
        """
        ALGORITHME SIMPLIFIÃ‰ : RÃ©assemble en respectant exactement les sÃ©parateurs mÃ©morisÃ©s

        Logique simple :
        1. Pour chaque segment de type 'line' : ajouter le texte traduit
        2. Pour chaque segment de type 'code' : ajouter le code non traduit
        3. Pour chaque segment de type 'separator' : ajouter exactement les \n mÃ©morisÃ©s
        4. Restaurer les emojis Ã  la fin

        Args:
            translated_segments: Liste de segments avec 'text' et 'type'
            emojis_map: Mapping des emojis Ã  restaurer
        """
        result_parts = []

        for segment in translated_segments:
            segment_type = segment['type']
            segment_text = segment['text']

            if segment_type == 'separator':
                # Ajouter exactement le sÃ©parateur mÃ©morisÃ© (\n, \n\n, \n\n\n, etc.)
                result_parts.append(segment_text)
            elif segment_type in ['line', 'code']:
                # Ajouter la ligne (traduite si 'line', originale si 'code')
                result_parts.append(segment_text)
            elif segment_type == 'empty_line':
                # Ligne vide - ne rien ajouter (le sÃ©parateur suivant gÃ©rera les \n)
                pass

        # Joindre toutes les parties
        reassembled = ''.join(result_parts)

        # Restaurer les emojis avec post-traitement robuste
        final_text = self.restore_emojis(reassembled, emojis_map)

        logger.info(f"[SEGMENTER] Text reassembled: {len(final_text)} chars from {len(translated_segments)} segments")
        return final_text


def test_segmenter():
    """Test du segmenteur"""
    segmenter = TextSegmenter(max_segment_length=50)

    test_text = """Hello! ğŸ˜Š How are you today?

This is a new paragraph with some emojis ğŸ‰ğŸŠ.

And this is the final paragraph! ğŸš€"""

    print("Original text:")
    print(test_text)
    print("\n" + "="*50 + "\n")

    # Segmenter
    segments, emojis = segmenter.segment_text(test_text)

    print("Segments:")
    for seg in segments:
        print(f"[{seg['type']}] {repr(seg['text'])}")

    print(f"\nEmojis extracted: {emojis}")

    # Simuler une traduction (garder tel quel)
    translated = [{'text': s['text'], 'type': s['type'], 'index': s['index']} for s in segments]

    # RÃ©assembler
    result = segmenter.reassemble_text(translated, emojis)

    print("\n" + "="*50 + "\n")
    print("Reassembled text:")
    print(result)

    print("\n" + "="*50 + "\n")
    print(f"Match original: {result == test_text}")


if __name__ == "__main__":
    test_segmenter()

"""
Serveur ZeroMQ haute performance pour le service de traduction Meeshy
Architecture: PUB/SUB + REQ/REP avec pool de connexions et traitement asynchrone
"""

import asyncio
import json
import logging
import uuid
import zmq
import zmq.asyncio
import re
from dataclasses import dataclass
from typing import Dict, List, Optional, Set
from concurrent.futures import ThreadPoolExecutor
import time
import psutil
from collections import defaultdict

# Import du service de base de donnÃ©es
from .database_service import DatabaseService

# Import de la configuration des limites
from config.message_limits import can_translate_message, MessageLimits

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class TranslationTask:
    """TÃ¢che de traduction avec support multi-langues"""
    task_id: str
    message_id: str
    text: str
    source_language: str
    target_languages: List[str]
    conversation_id: str
    model_type: str = "basic"
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()

class TranslationPoolManager:
    """Gestionnaire des pools FIFO de traduction avec gestion dynamique des workers"""
    
    def __init__(self, 
                 normal_pool_size: int = 10000,
                 any_pool_size: int = 10000,
                 normal_workers: int = 20,  # AugmentÃ© pour haute performance
                 any_workers: int = 10,     # AugmentÃ© pour haute performance
                 translation_service=None,
                 enable_dynamic_scaling: bool = True):
        
        # Pools FIFO sÃ©parÃ©es
        self.normal_pool = asyncio.Queue(maxsize=normal_pool_size)
        self.any_pool = asyncio.Queue(maxsize=any_pool_size)
        
        # Configuration des workers avec valeurs par dÃ©faut configurables
        import os
        
        # Valeurs par dÃ©faut configurables
        self.normal_workers_default = int(os.getenv('NORMAL_WORKERS_DEFAULT', '20'))
        self.any_workers_default = int(os.getenv('ANY_WORKERS_DEFAULT', '10'))
        
        # Limites minimales configurables
        self.normal_workers_min = int(os.getenv('NORMAL_WORKERS_MIN', '2'))
        self.any_workers_min = int(os.getenv('ANY_WORKERS_MIN', '2'))
        
        # Limites maximales configurables
        self.normal_workers_max = int(os.getenv('NORMAL_WORKERS_MAX', '40'))
        self.any_workers_max = int(os.getenv('ANY_WORKERS_MAX', '20'))
        
        # Utiliser les valeurs fournies ou les valeurs par dÃ©faut
        self.normal_workers = normal_workers if normal_workers is not None else self.normal_workers_default
        self.any_workers = any_workers if any_workers is not None else self.any_workers_default
        
        # S'assurer que les valeurs sont dans les limites
        self.normal_workers = max(self.normal_workers_min, min(self.normal_workers, self.normal_workers_max))
        self.any_workers = max(self.any_workers_min, min(self.any_workers, self.any_workers_max))
        
        # Limites max pour scaling (peuvent Ãªtre diffÃ©rentes des limites absolues)
        self.max_normal_workers = int(os.getenv('NORMAL_WORKERS_SCALING_MAX', str(self.normal_workers_max)))
        self.max_any_workers = int(os.getenv('ANY_WORKERS_SCALING_MAX', str(self.any_workers_max)))
        
        # Log de la configuration
        logger.info(f"[TRANSLATOR] ðŸ”§ Configuration workers:")
        logger.info(f"  Normal: {self.normal_workers} (min: {self.normal_workers_min}, max: {self.normal_workers_max}, scaling_max: {self.max_normal_workers})")
        logger.info(f"  Any: {self.any_workers} (min: {self.any_workers_min}, max: {self.any_workers_max}, scaling_max: {self.max_any_workers})")
        
        # Gestion dynamique
        self.enable_dynamic_scaling = enable_dynamic_scaling
        self.scaling_check_interval = 30  # VÃ©rifier toutes les 30 secondes
        self.last_scaling_check = time.time()
        
        # Thread pools pour les traductions
        self.normal_worker_pool = ThreadPoolExecutor(max_workers=self.max_normal_workers)
        self.any_worker_pool = ThreadPoolExecutor(max_workers=self.max_any_workers)
        
        # Service de traduction partagÃ©
        self.translation_service = translation_service
        
        # Statistiques avancÃ©es
        self.stats = {
            'normal_pool_size': 0,
            'any_pool_size': 0,
            'normal_workers_active': 0,
            'any_workers_active': 0,
            'tasks_processed': 0,
            'tasks_failed': 0,
            'translations_completed': 0,
            'pool_full_rejections': 0,
            'avg_processing_time': 0.0,
            'queue_growth_rate': 0.0,
            'worker_utilization': 0.0,
            'dynamic_scaling_events': 0
        }
        
        # Workers actifs
        self.normal_workers_running = False
        self.any_workers_running = False
        self.normal_worker_tasks = []
        self.any_worker_tasks = []
        
        logger.info(f"[TRANSLATOR] TranslationPoolManager haute performance initialisÃ©: normal_pool({normal_pool_size}), any_pool({any_pool_size}), normal_workers({normal_workers}), any_workers({any_workers})")
        logger.info(f"[TRANSLATOR] Gestion dynamique des workers: {'activÃ©e' if enable_dynamic_scaling else 'dÃ©sactivÃ©e'}")
    
    async def enqueue_task(self, task: TranslationTask) -> bool:
        """Enfile une tÃ¢che dans la pool appropriÃ©e"""
        try:
            if task.conversation_id == "any":
                # Pool spÃ©ciale pour conversation "any"
                if self.any_pool.full():
                    logger.warning(f"Pool 'any' pleine, rejet de la tÃ¢che {task.task_id}")
                    self.stats['pool_full_rejections'] += 1
                    return False
                
                await self.any_pool.put(task)
                self.stats['any_pool_size'] = self.any_pool.qsize()
                logger.info(f"TÃ¢che {task.task_id} enfilÃ©e dans pool 'any' (taille: {self.stats['any_pool_size']})")
            else:
                # Pool normale pour autres conversations
                if self.normal_pool.full():
                    logger.warning(f"Pool normale pleine, rejet de la tÃ¢che {task.task_id}")
                    self.stats['pool_full_rejections'] += 1
                    return False
                
                await self.normal_pool.put(task)
                self.stats['normal_pool_size'] = self.normal_pool.qsize()
                logger.info(f"TÃ¢che {task.task_id} enfilÃ©e dans pool normale (taille: {self.stats['normal_pool_size']})")
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de l'enfilage de la tÃ¢che {task.task_id}: {e}")
            return False
    
    async def start_workers(self):
        """DÃ©marre tous les workers avec gestion dynamique"""
        logger.info(f"[TRANSLATOR] ðŸ”„ DÃ©but du dÃ©marrage des workers...")
        self.normal_workers_running = True
        self.any_workers_running = True
        
        logger.info(f"[TRANSLATOR] ðŸ”„ CrÃ©ation des workers normaux ({self.normal_workers})...")
        # DÃ©marrer les workers pour la pool normale
        self.normal_worker_tasks = [
            asyncio.create_task(self._normal_worker_loop(f"normal_worker_{i}"))
            for i in range(self.normal_workers)
        ]
        logger.info(f"[TRANSLATOR] âœ… Workers normaux crÃ©Ã©s: {len(self.normal_worker_tasks)}")
        
        logger.info(f"[TRANSLATOR] ðŸ”„ CrÃ©ation des workers 'any' ({self.any_workers})...")
        # DÃ©marrer les workers pour la pool "any"
        self.any_worker_tasks = [
            asyncio.create_task(self._any_worker_loop(f"any_worker_{i}"))
            for i in range(self.any_workers)
        ]
        logger.info(f"[TRANSLATOR] âœ… Workers 'any' crÃ©Ã©s: {len(self.any_worker_tasks)}")
        
        logger.info(f"[TRANSLATOR] Workers haute performance dÃ©marrÃ©s: {self.normal_workers} normal, {self.any_workers} any")
        logger.info(f"[TRANSLATOR] CapacitÃ© totale: {self.normal_workers + self.any_workers} traductions simultanÃ©es")
        return self.normal_worker_tasks + self.any_worker_tasks
    
    async def stop_workers(self):
        """ArrÃªte tous les workers"""
        self.normal_workers_running = False
        self.any_workers_running = False
        logger.info("ArrÃªt des workers demandÃ©")
    
    async def _dynamic_scaling_check(self):
        """VÃ©rifie et ajuste dynamiquement le nombre de workers"""
        if not self.enable_dynamic_scaling:
            return
            
        current_time = time.time()
        if current_time - self.last_scaling_check < self.scaling_check_interval:
            return
            
        self.last_scaling_check = current_time
        
        # Calculer les mÃ©triques
        normal_queue_size = self.normal_pool.qsize()
        any_queue_size = self.any_pool.qsize()
        normal_utilization = self.stats['normal_workers_active'] / self.normal_workers if self.normal_workers > 0 else 0
        any_utilization = self.stats['any_workers_active'] / self.any_workers if self.any_workers > 0 else 0
        
        # Ajuster les workers normaux
        if normal_queue_size > 100 and normal_utilization > 0.8 and self.normal_workers < self.max_normal_workers:
            new_normal_workers = min(self.normal_workers + 5, self.max_normal_workers)
            if new_normal_workers > self.normal_workers:
                logger.info(f"[TRANSLATOR] ðŸ”§ Scaling UP normal workers: {self.normal_workers} â†’ {new_normal_workers}")
                await self._scale_normal_workers(new_normal_workers)
        
        elif normal_queue_size < 10 and normal_utilization < 0.3 and self.normal_workers > self.normal_workers_min:
            new_normal_workers = max(self.normal_workers - 2, self.normal_workers_min)
            if new_normal_workers < self.normal_workers:
                logger.info(f"[TRANSLATOR] ðŸ”§ Scaling DOWN normal workers: {self.normal_workers} â†’ {new_normal_workers}")
                await self._scale_normal_workers(new_normal_workers)
        
        # Ajuster les workers "any"
        if any_queue_size > 50 and any_utilization > 0.8 and self.any_workers < self.max_any_workers:
            new_any_workers = min(self.any_workers + 3, self.max_any_workers)
            if new_any_workers > self.any_workers:
                logger.info(f"[TRANSLATOR] ðŸ”§ Scaling UP any workers: {self.any_workers} â†’ {new_any_workers}")
                await self._scale_any_workers(new_any_workers)
        
        elif any_queue_size < 5 and any_utilization < 0.3 and self.any_workers > self.any_workers_min:
            new_any_workers = max(self.any_workers - 1, self.any_workers_min)
            if new_any_workers < self.any_workers:
                logger.info(f"[TRANSLATOR] ðŸ”§ Scaling DOWN any workers: {self.any_workers} â†’ {new_any_workers}")
                await self._scale_any_workers(new_any_workers)
    
    async def _scale_normal_workers(self, new_count: int):
        """Ajuste le nombre de workers normaux"""
        if new_count > self.normal_workers:
            # Ajouter des workers
            for i in range(self.normal_workers, new_count):
                task = asyncio.create_task(self._normal_worker_loop(f"normal_worker_{i}"))
                self.normal_worker_tasks.append(task)
        else:
            # RÃ©duire les workers (ils s'arrÃªteront naturellement)
            pass
        
        self.normal_workers = new_count
        self.stats['dynamic_scaling_events'] += 1
    
    async def _scale_any_workers(self, new_count: int):
        """Ajuste le nombre de workers any"""
        if new_count > self.any_workers:
            # Ajouter des workers
            for i in range(self.any_workers, new_count):
                task = asyncio.create_task(self._any_worker_loop(f"any_worker_{i}"))
                self.any_worker_tasks.append(task)
        else:
            # RÃ©duire les workers (ils s'arrÃªteront naturellement)
            pass
        
        self.any_workers = new_count
        self.stats['dynamic_scaling_events'] += 1
    
    async def _normal_worker_loop(self, worker_name: str):
        """Boucle de travail pour les workers de la pool normale avec scaling dynamique"""
        logger.info(f"Worker {worker_name} dÃ©marrÃ©")
        
        while self.normal_workers_running:
            try:
                # VÃ©rifier le scaling dynamique
                await self._dynamic_scaling_check()
                
                # Attendre une tÃ¢che avec timeout
                try:
                    task = await asyncio.wait_for(self.normal_pool.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                self.stats['normal_workers_active'] += 1
                self.stats['normal_pool_size'] = self.normal_pool.qsize()
                
                logger.debug(f"Worker {worker_name} traite la tÃ¢che {task.task_id} ({len(task.target_languages)} langues)")
                
                # Traiter la tÃ¢che
                start_time = time.time()
                await self._process_translation_task(task, worker_name)
                processing_time = time.time() - start_time
                
                # Mettre Ã  jour les stats de performance
                self.stats['avg_processing_time'] = (
                    (self.stats['avg_processing_time'] * (self.stats['tasks_processed']) + processing_time) 
                    / (self.stats['tasks_processed'] + 1)
                )
                
                self.stats['normal_workers_active'] -= 1
                self.stats['tasks_processed'] += 1
                
            except Exception as e:
                logger.error(f"Erreur dans le worker {worker_name}: {e}")
                self.stats['tasks_failed'] += 1
                if self.stats['normal_workers_active'] > 0:
                    self.stats['normal_workers_active'] -= 1
        
        logger.info(f"Worker {worker_name} arrÃªtÃ©")
    
    async def _any_worker_loop(self, worker_name: str):
        """Boucle de travail pour les workers de la pool 'any' avec scaling dynamique"""
        logger.info(f"Worker {worker_name} dÃ©marrÃ©")
        
        while self.any_workers_running:
            try:
                # VÃ©rifier le scaling dynamique
                await self._dynamic_scaling_check()
                
                # Attendre une tÃ¢che avec timeout
                try:
                    task = await asyncio.wait_for(self.any_pool.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                self.stats['any_workers_active'] += 1
                self.stats['any_pool_size'] = self.any_pool.qsize()
                
                logger.debug(f"Worker {worker_name} traite la tÃ¢che {task.task_id} ({len(task.target_languages)} langues)")
                
                # Traiter la tÃ¢che
                start_time = time.time()
                await self._process_translation_task(task, worker_name)
                processing_time = time.time() - start_time
                
                # Mettre Ã  jour les stats de performance
                self.stats['avg_processing_time'] = (
                    (self.stats['avg_processing_time'] * (self.stats['tasks_processed']) + processing_time) 
                    / (self.stats['tasks_processed'] + 1)
                )
                
                self.stats['any_workers_active'] -= 1
                self.stats['tasks_processed'] += 1
                
            except Exception as e:
                logger.error(f"Erreur dans le worker {worker_name}: {e}")
                self.stats['tasks_failed'] += 1
                if self.stats['any_workers_active'] > 0:
                    self.stats['any_workers_active'] -= 1
        
        logger.info(f"Worker {worker_name} arrÃªtÃ©")
    
    async def _process_translation_task(self, task: TranslationTask, worker_name: str):
        """Traite une tÃ¢che de traduction avec traduction parallÃ¨le"""
        try:
            # Lancer les traductions en parallÃ¨le
            translation_tasks = []
            
            for target_language in task.target_languages:
                translation_task = asyncio.create_task(
                    self._translate_single_language(task, target_language, worker_name)
                )
                translation_tasks.append((target_language, translation_task))
            
            # Attendre toutes les traductions
            for target_language, translation_task in translation_tasks:
                try:
                    result = await translation_task
                    # Ajouter le type de pool au rÃ©sultat
                    result['poolType'] = 'any' if task.conversation_id == 'any' else 'normal'
                    result['created_at'] = task.created_at
                    # Publier le rÃ©sultat via PUB
                    await self._publish_translation_result(task.task_id, result, target_language)
                    self.stats['translations_completed'] += 1
                    
                except Exception as e:
                    logger.error(f"Erreur de traduction pour {target_language} dans {task.task_id}: {e}")
                    # Publier un rÃ©sultat d'erreur
                    error_result = self._create_error_result(task, target_language, str(e))
                    await self._publish_translation_result(task.task_id, error_result, target_language)
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la tÃ¢che {task.task_id}: {e}")
            self.stats['tasks_failed'] += 1
    
    async def _translate_single_language(self, task: TranslationTask, target_language: str, worker_name: str):
        """Traduit un texte vers une langue cible spÃ©cifique"""
        start_time = time.time()
        
        try:
            # Utiliser le service de traduction partagÃ©
            if self.translation_service:
                # Effectuer la vraie traduction avec le service ML unifiÃ©
                result = await self.translation_service.translate(
                    text=task.text,
                    source_language=task.source_language,
                    target_language=target_language,
                    model_type=task.model_type,
                    source_channel='zmq'  # Identifier le canal source
                )
                
                processing_time = time.time() - start_time
                
                # VÃ©rifier si le rÃ©sultat est None ou invalide
                if result is None:
                    logger.error(f"âŒ [TRANSLATOR] Service ML a retournÃ© None pour {worker_name}")
                    raise Exception("Service de traduction a retournÃ© None")
                
                # VÃ©rifier que le rÃ©sultat contient les clÃ©s attendues
                if not isinstance(result, dict) or 'translated_text' not in result:
                    logger.error(f"âŒ [TRANSLATOR] RÃ©sultat invalide pour {worker_name}: {result}")
                    raise Exception(f"RÃ©sultat de traduction invalide: {result}")
                
                return {
                    'messageId': task.message_id,
                    'translatedText': result['translated_text'],
                    'sourceLanguage': result.get('detected_language', task.source_language),
                    'targetLanguage': target_language,
                    'confidenceScore': result.get('confidence', 0.95),
                    'processingTime': processing_time,
                    'modelType': task.model_type,
                    'workerName': worker_name
                }
            else:
                # Fallback si pas de service de traduction
                translated_text = f"[{target_language.upper()}] {task.text}"
                processing_time = time.time() - start_time
                
                return {
                    'messageId': task.message_id,
                    'translatedText': translated_text,
                    'sourceLanguage': task.source_language,
                    'targetLanguage': target_language,
                    'confidenceScore': 0.1,
                    'processingTime': processing_time,
                    'modelType': 'fallback',
                    'workerName': worker_name,
                    'error': 'No translation service available'
                }
            
        except Exception as e:
            logger.error(f"Erreur de traduction dans {worker_name}: {e}")
            # Fallback en cas d'erreur
            translated_text = f"[{target_language.upper()}] {task.text}"
            processing_time = time.time() - start_time
            
            return {
                'messageId': task.message_id,
                'translatedText': translated_text,
                'sourceLanguage': task.source_language,
                'targetLanguage': target_language,
                'confidenceScore': 0.1,
                'processingTime': processing_time,
                'modelType': 'fallback',
                'workerName': worker_name,
                'error': str(e)
            }
    
    def _create_error_result(self, task: TranslationTask, target_language: str, error_message: str):
        """CrÃ©e un rÃ©sultat d'erreur pour une traduction Ã©chouÃ©e"""
        return {
            'messageId': task.message_id,
            'translatedText': f"[ERREUR: {error_message}]",
            'sourceLanguage': task.source_language,
            'targetLanguage': target_language,
            'confidenceScore': 0.0,
            'processingTime': 0.0,
            'modelType': task.model_type,
            'error': error_message
        }
    
    async def _publish_translation_result(self, task_id: str, result: dict, target_language: str):
        """Publie un rÃ©sultat de traduction via PUB"""
        try:
            # Cette mÃ©thode sera appelÃ©e par le serveur ZMQ principal
            # Le rÃ©sultat sera publiÃ© via le socket PUB
            # Note: Cette mÃ©thode sera remplacÃ©e par le serveur ZMQ principal
            pass
        except Exception as e:
            logger.error(f"Erreur lors de la publication du rÃ©sultat {task_id}: {e}")
    
    def get_stats(self) -> dict:
        """Retourne les statistiques actuelles"""
        return {
            **self.stats,
            'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
            'uptime_seconds': time.time() - getattr(self, '_start_time', time.time())
        }

class ZMQTranslationServer:
    """Serveur ZMQ pour la traduction avec architecture PUB/SUB"""
    
    def __init__(self, 
                 host: str = "0.0.0.0",
                 gateway_push_port: int = 5555,  # Port oÃ¹ Translator PULL bind (Gateway PUSH connect ici)
                 gateway_sub_port: int = 5558,   # Port oÃ¹ Translator PUB bind (Gateway SUB connect ici)
                 normal_pool_size: int = 10000,
                 any_pool_size: int = 10000,
                 normal_workers: int = 3,
                 any_workers: int = 2,
                 translation_service=None,
                 database_url: str = None):
        
        self.host = host
        self.gateway_push_port = gateway_push_port  # Port pour PULL (recevoir commandes)
        self.gateway_sub_port = gateway_sub_port    # Port pour PUB (envoyer rÃ©ponses)
        self.context = zmq.asyncio.Context()
        
        # Sockets
        self.pull_socket = None  # PULL pour recevoir les commandes de traduction
        self.pub_socket = None   # PUB pour publier les rÃ©sultats (inchangÃ©)
        
        # Pool manager
        self.pool_manager = TranslationPoolManager(
            normal_pool_size=normal_pool_size,
            any_pool_size=any_pool_size,
            normal_workers=normal_workers,
            any_workers=any_workers,
            translation_service=translation_service
        )
        
        # Remplacer la mÃ©thode de publication du pool manager
        self.pool_manager._publish_translation_result = self._publish_translation_result
        
        # Service de base de donnÃ©es
        self.database_service = DatabaseService(database_url)
        
        # Ã‰tat du serveur
        self.running = False
        self.worker_tasks = []
        
        logger.info(f"ZMQTranslationServer initialisÃ©: Gateway PUSH {host}:{gateway_push_port} (PULL bind)")
        logger.info(f"ZMQTranslationServer initialisÃ©: Gateway SUB {host}:{gateway_sub_port} (PUB bind)")

    async def _connect_database_background(self):
        """Connecte Ã  la base de donnÃ©es en arriÃ¨re-plan sans bloquer le dÃ©marrage"""
        try:
            logger.info("[TRANSLATOR-DB] ðŸ”— Tentative de connexion Ã  MongoDB...")
            db_connected = await self.database_service.connect()
            if db_connected:
                logger.info("[TRANSLATOR-DB] âœ… Connexion Ã  la base de donnÃ©es Ã©tablie")
            else:
                logger.warning("[TRANSLATOR-DB] âš ï¸ Connexion Ã  la base de donnÃ©es Ã©chouÃ©e, sauvegarde dÃ©sactivÃ©e")
        except Exception as e:
            logger.error(f"[TRANSLATOR-DB] âŒ Erreur lors de la connexion Ã  la base de donnÃ©es: {e}")
    
    async def initialize(self):
        """Initialise les sockets ZMQ avec architecture PUSH/PULL + PUB/SUB"""
        try:
            # Connexion Ã  la base de donnÃ©es en arriÃ¨re-plan (non-bloquante)
            logger.info("[TRANSLATOR] ðŸ”— Lancement de la connexion Ã  la base de donnÃ©es en arriÃ¨re-plan...")
            # CrÃ©er une tÃ¢che asynchrone pour la connexion DB sans bloquer
            asyncio.create_task(self._connect_database_background())
            logger.info("[TRANSLATOR] âœ… Connexion DB lancÃ©e en arriÃ¨re-plan, le serveur continue son dÃ©marrage...")
            
            # Socket PULL pour recevoir les commandes du Gateway (remplace SUB)
            self.pull_socket = self.context.socket(zmq.PULL)
            self.pull_socket.bind(f"tcp://{self.host}:{self.gateway_push_port}")
            
            # Socket PUB pour publier les rÃ©sultats vers le Gateway (inchangÃ©)
            self.pub_socket = self.context.socket(zmq.PUB)
            self.pub_socket.bind(f"tcp://{self.host}:{self.gateway_sub_port}")
            
            # Petit dÃ©lai pour Ã©tablir les connexions ZMQ
            await asyncio.sleep(0.1)
            logger.info("[TRANSLATOR] âœ… Sockets ZMQ crÃ©Ã©s, dÃ©marrage des workers...")
            
            # DÃ©marrer les workers
            self.worker_tasks = await self.pool_manager.start_workers()
            logger.info(f"[TRANSLATOR] âœ… Workers dÃ©marrÃ©s: {len(self.worker_tasks)} tÃ¢ches")
            
            logger.info("ZMQTranslationServer initialisÃ© avec succÃ¨s")
            logger.info(f"ðŸ”Œ Socket PULL liÃ© au port: {self.host}:{self.gateway_push_port}")
            logger.info(f"ðŸ”Œ Socket PUB liÃ© au port: {self.host}:{self.gateway_sub_port}")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation: {e}")
            raise
    
    async def start(self):
        """DÃ©marre le serveur"""
        if not self.pull_socket or not self.pub_socket:
            await self.initialize()
        
        self.running = True
        logger.info("ZMQTranslationServer dÃ©marrÃ©")
        
        try:
            while self.running:
                try:
                    # Recevoir une commande de traduction via PULL
                    message = await self.pull_socket.recv()
                    await self._handle_translation_request(message)
                    
                except zmq.ZMQError as e:
                    if self.running:
                        logger.error(f"Erreur ZMQ: {e}")
                    break
                except Exception as e:
                    logger.error(f"Erreur inattendue: {e}")
                    import traceback
                    traceback.print_exc()
                    
        except KeyboardInterrupt:
            logger.info("ArrÃªt demandÃ© par l'utilisateur")
        finally:
            await self.stop()
    
    async def _handle_translation_request(self, message: bytes):
        """Traite une requÃªte de traduction reÃ§ue via SUB"""
        try:
            request_data = json.loads(message.decode('utf-8'))
            
            # VÃ©rifier si c'est un message de ping
            if request_data.get('type') == 'ping':
                logger.info(f"ðŸ“ [TRANSLATOR] Ping reÃ§u, timestamp: {request_data.get('timestamp')}")
                # RÃ©pondre au ping via PUB
                ping_response = {
                    'type': 'pong',
                    'timestamp': time.time(),
                    'translator_status': 'alive',
                    'translator_port_pub': self.gateway_sub_port,
                    'translator_port_pull': self.gateway_push_port
                }
                if self.pub_socket:
                    await self.pub_socket.send(json.dumps(ping_response).encode('utf-8'))
                    logger.info(f"ðŸ“ [TRANSLATOR] Pong envoyÃ© via port {self.gateway_sub_port}")
                else:
                    logger.error(f"âŒ [TRANSLATOR] Socket PUB non disponible pour pong (port {self.gateway_sub_port})")
                return
            
            # VÃ©rifier que c'est une requÃªte de traduction valide
            if not request_data.get('text') or not request_data.get('targetLanguages'):
                logger.warning(f"âš ï¸ [TRANSLATOR] RequÃªte invalide reÃ§ue: {request_data}")
                return
            
            # VÃ©rifier la longueur du message pour la traduction
            message_text = request_data.get('text', '')
            if not can_translate_message(message_text):
                logger.warning(f"âš ï¸ [TRANSLATOR] Message too long to be translated: {len(message_text)} caractÃ¨res (max: {MessageLimits.MAX_TRANSLATION_LENGTH})")
                # Ne pas traiter ce message, retourner un rÃ©sultat vide ou le texte original
                # On pourrait aussi envoyer une notification Ã  la gateway ici si nÃ©cessaire
                no_translation_message = {
                    'type': 'translation_skipped',
                    'messageId': request_data.get('messageId'),
                    'reason': 'message_too_long',
                    'length': len(message_text),
                    'max_length': MessageLimits.MAX_TRANSLATION_LENGTH,
                    'conversationId': request_data.get('conversationId', 'unknown')
                }
                if self.pub_socket:
                    await self.pub_socket.send(json.dumps(no_translation_message).encode('utf-8'))
                    logger.info(f"[TRANSLATOR] translation message ignored for message {request_data.get('messageId')}")
                return
            
            # CrÃ©er la tÃ¢che de traduction
            task = TranslationTask(
                task_id=str(uuid.uuid4()),
                message_id=request_data.get('messageId'),
                text=message_text,
                source_language=request_data.get('sourceLanguage', 'fr'),
                target_languages=request_data.get('targetLanguages', []),
                conversation_id=request_data.get('conversationId', 'unknown'),
                model_type=request_data.get('modelType', 'basic')
            )
            
            logger.info(f"ðŸ”§ [TRANSLATOR] TÃ¢che crÃ©Ã©e: {task.task_id} pour {task.conversation_id} ({len(task.target_languages)} langues)")
            logger.info(f"ðŸ“ [TRANSLATOR] DÃ©tails: texte='{task.text[:50]}...', source={task.source_language}, target={task.target_languages}, modÃ¨le={task.model_type}")
            
            # Enfiler la tÃ¢che dans la pool appropriÃ©e
            success = await self.pool_manager.enqueue_task(task)
            
            if not success:
                # Pool pleine, publier un message d'erreur vers la gateway
                error_message = {
                    'type': 'translation_error',
                    'taskId': task.task_id,
                    'messageId': task.message_id,
                    'error': 'translation pool full',
                    'conversationId': task.conversation_id
                }
                # Utiliser le socket PUB configurÃ© pour envoyer l'erreur Ã  la gateway
                if self.pub_socket:
                    await self.pub_socket.send(json.dumps(error_message).encode('utf-8'))
                    logger.warning(f"Pool pleine, rejet de la tÃ¢che {task.task_id}")
                else:
                    logger.error("âŒ Socket PUB non initialisÃ© pour envoyer l'erreur")
            
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de dÃ©codage JSON: {e}")
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la requÃªte: {e}")
    
    async def _publish_translation_result(self, task_id: str, result: dict, target_language: str):
        """Publie un rÃ©sultat de traduction via PUB vers la gateway avec informations techniques complÃ¨tes"""
        try:
            # DEBUG: Logs rÃ©duits de 60% - Suppression des vÃ©rifications dÃ©taillÃ©es
            
            # RÃ©cupÃ©rer les informations techniques du systÃ¨me
            import socket
            import uuid
            
            # Calculer le temps d'attente en queue
            queue_time = time.time() - result.get('created_at', time.time())
            
            # RÃ©cupÃ©rer les mÃ©triques systÃ¨me
            memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            cpu_usage = psutil.Process().cpu_percent()
            # Attendre un peu pour avoir une mesure CPU valide
            await asyncio.sleep(0.1)
            cpu_usage = psutil.Process().cpu_percent()
            
            # Enrichir le rÃ©sultat avec toutes les informations techniques
            enriched_result = {
                # Informations applicatives existantes
                'messageId': result.get('messageId'),
                'translatedText': result.get('translatedText'),
                'sourceLanguage': result.get('sourceLanguage'),
                'targetLanguage': result.get('targetLanguage'),
                'confidenceScore': result.get('confidenceScore', 0.0),
                'processingTime': result.get('processingTime', 0.0),
                'modelType': result.get('modelType', 'basic'),
                'workerName': result.get('workerName', 'unknown'),
                
                # NOUVELLES INFORMATIONS TECHNIQUES
                'translatorModel': result.get('modelType', 'basic'),  # ModÃ¨le ML utilisÃ©
                'workerId': result.get('workerName', 'unknown'),      # Worker qui a traitÃ©
                'poolType': result.get('poolType', 'normal'),         # Pool utilisÃ©e (normal/any)
                'translationTime': result.get('processingTime', 0.0), # Temps de traduction
                'queueTime': queue_time,                              # Temps d'attente en queue
                'memoryUsage': memory_usage,                          # Usage mÃ©moire (MB)
                'cpuUsage': cpu_usage,                                # Usage CPU (%)
                'timestamp': time.time(),
                'version': '1.0.0'  # Version du Translator
            }
            
            # CrÃ©er le message enrichi
            message = {
                'type': 'translation_completed',
                'taskId': task_id,
                'result': enriched_result,
                'targetLanguage': target_language,
                'timestamp': time.time(),
                # MÃ‰TADONNÃ‰ES TECHNIQUES
                'metadata': {
                    'translatorVersion': '1.0.0',
                    'modelVersion': result.get('modelType', 'basic'),
                    'processingNode': socket.gethostname(),
                    'sessionId': str(uuid.uuid4()),
                    'requestId': task_id,
                    'protocol': 'ZMQ_PUB_SUB',
                    'encoding': 'UTF-8'
                }
            }
            
            # DEBUG: Logs rÃ©duits de 60% - Suppression des dÃ©tails techniques
            
            # VÃ‰RIFICATION DE LA QUALITÃ‰ DE LA TRADUCTION
            translated_text = result.get('translatedText', '')
            is_valid_translation = self._is_valid_translation(translated_text, result)
            
            if not is_valid_translation:
                # Traduction invalide - NE PAS ENVOYER Ã  la Gateway
                logger.error(f"âŒ [TRANSLATOR] Traduction invalide dÃ©tectÃ©e - PAS D'ENVOI Ã  la Gateway:")
                logger.error(f"   ðŸ“‹ Task ID: {task_id}")
                logger.error(f"   ðŸ“‹ Message ID: {result.get('messageId')}")
                logger.error(f"   ðŸ“‹ Source: {result.get('sourceLanguage')} -> Target: {target_language}")
                logger.error(f"   ðŸ“‹ Texte original: {result.get('originalText', 'N/A')}")
                logger.error(f"   ðŸ“‹ Texte traduit: '{translated_text}'")
                logger.error(f"   ðŸ“‹ ModÃ¨le utilisÃ©: {result.get('modelType', 'unknown')}")
                logger.error(f"   ðŸ“‹ Worker: {result.get('workerName', 'unknown')}")
                logger.error(f"   ðŸ“‹ Raison: {self._get_translation_error_reason(translated_text)}")
                return  # Sortir sans envoyer Ã  la Gateway
            
            # Traduction valide - SAUVEGARDE ET ENVOI
            try:
                # PrÃ©parer les donnÃ©es pour la sauvegarde
                save_data = {
                    'messageId': result.get('messageId'),
                    'sourceLanguage': result.get('sourceLanguage'),
                    'targetLanguage': result.get('targetLanguage'),
                    'translatedText': result.get('translatedText'),
                    'translatorModel': result.get('translatorModel', result.get('modelType', 'basic')),
                    'confidenceScore': result.get('confidenceScore', 0.9),
                    'processingTime': result.get('processingTime', 0.0),
                    'workerName': result.get('workerName', 'unknown'),
                    'poolType': result.get('poolType', 'normal')
                }
                
                # Sauvegarder en base de donnÃ©es (si connectÃ©)
                if self.database_service.is_db_connected():
                    save_success = await self.database_service.save_translation(save_data)
                    if save_success:
                        logger.info(f"ðŸ’¾ [TRANSLATOR] Traduction sauvegardÃ©e en base: {result.get('messageId')} -> {target_language}")
                    else:
                        logger.warning(f"âš ï¸ [TRANSLATOR] Ã‰chec sauvegarde en base: {result.get('messageId')} -> {target_language}")
                else:
                    logger.info(f"ðŸ“‹ [TRANSLATOR] Base de donnÃ©es non connectÃ©e, pas de sauvegarde pour: {result.get('messageId')} -> {target_language}")
                    
            except Exception as e:
                logger.error(f"âŒ [TRANSLATOR] Erreur sauvegarde base de donnÃ©es: {e}")
            
            # ENVOI Ã€ LA GATEWAY (seulement si traduction valide)
            if self.pub_socket:
                await self.pub_socket.send(json.dumps(message).encode('utf-8'))
                logger.info(f"ðŸ“¤ [TRANSLATOR] RÃ©sultat envoyÃ© Ã  la Gateway: {task_id} -> {target_language}")
            else:
                logger.error("âŒ Socket PUB non initialisÃ©")
            
        except Exception as e:
            logger.error(f"Erreur lors de la publication du rÃ©sultat enrichi: {e}")
            import traceback
            traceback.print_exc()
    
    def _is_valid_translation(self, translated_text: str, result: dict) -> bool:
        """
        VÃ©rifie si une traduction est valide et peut Ãªtre envoyÃ©e Ã  la Gateway
        
        Args:
            translated_text: Le texte traduit
            result: Le rÃ©sultat complet de la traduction
        
        Returns:
            bool: True si la traduction est valide, False sinon
        """
        # VÃ©rifier que le texte traduit existe et n'est pas vide
        if not translated_text or translated_text.strip() == '':
            return False
        
        # VÃ©rifier que ce n'est pas un message d'erreur
        error_patterns = [
            r'^\[.*Error.*\]',
            r'^\[.*Failed.*\]',
            r'^\[.*No.*Result.*\]',
            r'^\[.*Fallback.*\]',
            r'^\[.*ML.*Error.*\]',
            r'^\[.*Ã‰CHEC.*\]',
            r'^\[.*MODÃˆLES.*NON.*\]',
            r'^\[.*MODÃˆLES.*NON.*CHARGÃ‰S.*\]',
            r'^\[.*T5.*No.*Result.*\]',
            r'^\[.*NLLB.*No.*Result.*\]',
            r'^\[.*T5.*Fallback.*\]',
            r'^\[.*NLLB.*Fallback.*\]',
            r'^\[.*ERREUR.*\]',
            r'^\[.*FAILED.*\]',
            r'^\[.*TIMEOUT.*\]',
            r'^\[.*META.*TENSOR.*\]'
        ]
        
        for pattern in error_patterns:
            if re.search(pattern, translated_text, re.IGNORECASE):
                return False
        
        # VÃ©rifier que le texte traduit n'est pas identique au texte source
        original_text = result.get('originalText', '')
        if original_text and translated_text.strip().lower() == original_text.strip().lower():
            return False
        
        # VÃ©rifier que le score de confiance est acceptable
        confidence_score = result.get('confidenceScore', 1.0)
        if confidence_score < 0.1:
            return False
        
        # VÃ©rifier qu'il n'y a pas d'erreur dans le rÃ©sultat
        if result.get('error'):
            return False
        
        return True
    
    def _get_translation_error_reason(self, translated_text: str) -> str:
        """
        Retourne la raison de l'Ã©chec de traduction
        
        Args:
            translated_text: Le texte traduit
        
        Returns:
            str: La raison de l'Ã©chec
        """
        if not translated_text or translated_text.strip() == '':
            return "Texte traduit vide"
        
        error_patterns = [
            (r'^\[.*Error.*\]', "Message d'erreur dÃ©tectÃ©"),
            (r'^\[.*Failed.*\]', "Ã‰chec de traduction dÃ©tectÃ©"),
            (r'^\[.*No.*Result.*\]', "Aucun rÃ©sultat de traduction"),
            (r'^\[.*Fallback.*\]', "Fallback de traduction dÃ©tectÃ©"),
            (r'^\[.*ML.*Error.*\]', "Erreur ML dÃ©tectÃ©e"),
            (r'^\[.*Ã‰CHEC.*\]', "Ã‰chec de traduction"),
            (r'^\[.*MODÃˆLES.*NON.*\]', "ModÃ¨les non disponibles"),
            (r'^\[.*MODÃˆLES.*NON.*CHARGÃ‰S.*\]', "ModÃ¨les non chargÃ©s"),
            (r'^\[.*T5.*No.*Result.*\]', "T5: Aucun rÃ©sultat"),
            (r'^\[.*NLLB.*No.*Result.*\]', "NLLB: Aucun rÃ©sultat"),
            (r'^\[.*T5.*Fallback.*\]', "T5: Fallback"),
            (r'^\[.*NLLB.*Fallback.*\]', "NLLB: Fallback"),
            (r'^\[.*ERREUR.*\]', "Erreur gÃ©nÃ©rale"),
            (r'^\[.*FAILED.*\]', "Ã‰chec gÃ©nÃ©ral"),
            (r'^\[.*TIMEOUT.*\]', "Timeout de traduction"),
            (r'^\[.*META.*TENSOR.*\]', "Erreur meta tensor")
        ]
        
        for pattern, reason in error_patterns:
            if re.search(pattern, translated_text, re.IGNORECASE):
                return reason
        
        return "Erreur de validation inconnue"
    
    async def stop(self):
        """ArrÃªte le serveur"""
        self.running = False
        
        # ArrÃªter les workers
        await self.pool_manager.stop_workers()
        
        # Attendre que tous les workers se terminent
        if self.worker_tasks:
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)
        
        # Fermer la connexion Ã  la base de donnÃ©es
        await self.database_service.disconnect()
        
        # Fermer les sockets
        if self.pull_socket:
            self.pull_socket.close()
        if self.pub_socket:
            self.pub_socket.close()
        
        logger.info("ZMQTranslationServer arrÃªtÃ©")
    
    def get_stats(self) -> dict:
        """Retourne les statistiques du serveur"""
        pool_stats = self.pool_manager.get_stats()
        
        return {
            'server_status': 'running' if self.running else 'stopped',
            'gateway_push_port': self.gateway_push_port,
            'gateway_sub_port': self.gateway_sub_port,
            'normal_workers': self.pool_manager.normal_workers,
            'any_workers': self.pool_manager.any_workers,
            **pool_stats
        }
    
    async def health_check(self) -> dict:
        """VÃ©rification de santÃ© du serveur"""
        try:
            stats = self.get_stats()
            return {
                'status': 'healthy',
                'running': self.running,
                'stats': stats
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

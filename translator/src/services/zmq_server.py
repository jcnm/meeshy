"""
Serveur ZeroMQ haute performance pour le service de traduction Meeshy
Architecture: PUB/SUB + REQ/REP avec pool de connexions et traitement asynchrone
"""

import asyncio
import json
import logging
import uuid
import zmq
import zmq.asyncio
from dataclasses import dataclass
from typing import Dict, List, Optional, Set
from concurrent.futures import ThreadPoolExecutor
import time
import psutil
from collections import defaultdict

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class TranslationTask:
    """T√¢che de traduction avec support multi-langues"""
    task_id: str
    message_id: str
    text: str
    source_language: str
    target_languages: List[str]
    conversation_id: str
    model_type: str = "basic"
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()

class TranslationPoolManager:
    """Gestionnaire des pools FIFO de traduction avec gestion dynamique des workers"""
    
    def __init__(self, 
                 normal_pool_size: int = 10000,
                 any_pool_size: int = 10000,
                 normal_workers: int = 20,  # Augment√© pour haute performance
                 any_workers: int = 10,     # Augment√© pour haute performance
                 translation_service=None,
                 enable_dynamic_scaling: bool = True):
        
        # Pools FIFO s√©par√©es
        self.normal_pool = asyncio.Queue(maxsize=normal_pool_size)
        self.any_pool = asyncio.Queue(maxsize=any_pool_size)
        
        # Configuration des workers
        self.normal_workers = normal_workers
        self.any_workers = any_workers
        self.max_normal_workers = normal_workers * 2  # Limite max pour scaling
        self.max_any_workers = any_workers * 2        # Limite max pour scaling
        
        # Gestion dynamique
        self.enable_dynamic_scaling = enable_dynamic_scaling
        self.scaling_check_interval = 30  # V√©rifier toutes les 30 secondes
        self.last_scaling_check = time.time()
        
        # Thread pools pour les traductions
        self.normal_worker_pool = ThreadPoolExecutor(max_workers=self.max_normal_workers)
        self.any_worker_pool = ThreadPoolExecutor(max_workers=self.max_any_workers)
        
        # Service de traduction partag√©
        self.translation_service = translation_service
        
        # Statistiques avanc√©es
        self.stats = {
            'normal_pool_size': 0,
            'any_pool_size': 0,
            'normal_workers_active': 0,
            'any_workers_active': 0,
            'tasks_processed': 0,
            'tasks_failed': 0,
            'translations_completed': 0,
            'pool_full_rejections': 0,
            'avg_processing_time': 0.0,
            'queue_growth_rate': 0.0,
            'worker_utilization': 0.0,
            'dynamic_scaling_events': 0
        }
        
        # Workers actifs
        self.normal_workers_running = False
        self.any_workers_running = False
        self.normal_worker_tasks = []
        self.any_worker_tasks = []
        
        logger.info(f"[TRANSLATOR] TranslationPoolManager haute performance initialis√©: normal_pool({normal_pool_size}), any_pool({any_pool_size}), normal_workers({normal_workers}), any_workers({any_workers})")
        logger.info(f"[TRANSLATOR] Gestion dynamique des workers: {'activ√©e' if enable_dynamic_scaling else 'd√©sactiv√©e'}")
    
    async def enqueue_task(self, task: TranslationTask) -> bool:
        """Enfile une t√¢che dans la pool appropri√©e"""
        try:
            if task.conversation_id == "any":
                # Pool sp√©ciale pour conversation "any"
                if self.any_pool.full():
                    logger.warning(f"Pool 'any' pleine, rejet de la t√¢che {task.task_id}")
                    self.stats['pool_full_rejections'] += 1
                    return False
                
                await self.any_pool.put(task)
                self.stats['any_pool_size'] = self.any_pool.qsize()
                logger.info(f"T√¢che {task.task_id} enfil√©e dans pool 'any' (taille: {self.stats['any_pool_size']})")
            else:
                # Pool normale pour autres conversations
                if self.normal_pool.full():
                    logger.warning(f"Pool normale pleine, rejet de la t√¢che {task.task_id}")
                    self.stats['pool_full_rejections'] += 1
                    return False
                
                await self.normal_pool.put(task)
                self.stats['normal_pool_size'] = self.normal_pool.qsize()
                logger.info(f"T√¢che {task.task_id} enfil√©e dans pool normale (taille: {self.stats['normal_pool_size']})")
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de l'enfilage de la t√¢che {task.task_id}: {e}")
            return False
    
    async def start_workers(self):
        """D√©marre tous les workers avec gestion dynamique"""
        self.normal_workers_running = True
        self.any_workers_running = True
        
        # D√©marrer les workers pour la pool normale
        self.normal_worker_tasks = [
            asyncio.create_task(self._normal_worker_loop(f"normal_worker_{i}"))
            for i in range(self.normal_workers)
        ]
        
        # D√©marrer les workers pour la pool "any"
        self.any_worker_tasks = [
            asyncio.create_task(self._any_worker_loop(f"any_worker_{i}"))
            for i in range(self.any_workers)
        ]
        
        logger.info(f"[TRANSLATOR] Workers haute performance d√©marr√©s: {self.normal_workers} normal, {self.any_workers} any")
        logger.info(f"[TRANSLATOR] Capacit√© totale: {self.normal_workers + self.any_workers} traductions simultan√©es")
        return self.normal_worker_tasks + self.any_worker_tasks
    
    async def stop_workers(self):
        """Arr√™te tous les workers"""
        self.normal_workers_running = False
        self.any_workers_running = False
        logger.info("Arr√™t des workers demand√©")
    
    async def _dynamic_scaling_check(self):
        """V√©rifie et ajuste dynamiquement le nombre de workers"""
        if not self.enable_dynamic_scaling:
            return
            
        current_time = time.time()
        if current_time - self.last_scaling_check < self.scaling_check_interval:
            return
            
        self.last_scaling_check = current_time
        
        # Calculer les m√©triques
        normal_queue_size = self.normal_pool.qsize()
        any_queue_size = self.any_pool.qsize()
        normal_utilization = self.stats['normal_workers_active'] / self.normal_workers if self.normal_workers > 0 else 0
        any_utilization = self.stats['any_workers_active'] / self.any_workers if self.any_workers > 0 else 0
        
        # Ajuster les workers normaux
        if normal_queue_size > 100 and normal_utilization > 0.8 and self.normal_workers < self.max_normal_workers:
            new_normal_workers = min(self.normal_workers + 5, self.max_normal_workers)
            if new_normal_workers > self.normal_workers:
                await self._scale_normal_workers(new_normal_workers)
                logger.info(f"[TRANSLATOR] üîß Scaling UP normal workers: {self.normal_workers} ‚Üí {new_normal_workers}")
        
        elif normal_queue_size < 10 and normal_utilization < 0.3 and self.normal_workers > 20:
            new_normal_workers = max(self.normal_workers - 2, 20)
            if new_normal_workers < self.normal_workers:
                await self._scale_normal_workers(new_normal_workers)
                logger.info(f"[TRANSLATOR] üîß Scaling DOWN normal workers: {self.normal_workers} ‚Üí {new_normal_workers}")
        
        # Ajuster les workers "any"
        if any_queue_size > 50 and any_utilization > 0.8 and self.any_workers < self.max_any_workers:
            new_any_workers = min(self.any_workers + 3, self.max_any_workers)
            if new_any_workers > self.any_workers:
                await self._scale_any_workers(new_any_workers)
                logger.info(f"[TRANSLATOR] üîß Scaling UP any workers: {self.any_workers} ‚Üí {new_any_workers}")
        
        elif any_queue_size < 5 and any_utilization < 0.3 and self.any_workers > 10:
            new_any_workers = max(self.any_workers - 1, 10)
            if new_any_workers < self.any_workers:
                await self._scale_any_workers(new_any_workers)
                logger.info(f"[TRANSLATOR] üîß Scaling DOWN any workers: {self.any_workers} ‚Üí {new_any_workers}")
    
    async def _scale_normal_workers(self, new_count: int):
        """Ajuste le nombre de workers normaux"""
        if new_count > self.normal_workers:
            # Ajouter des workers
            for i in range(self.normal_workers, new_count):
                task = asyncio.create_task(self._normal_worker_loop(f"normal_worker_{i}"))
                self.normal_worker_tasks.append(task)
        else:
            # R√©duire les workers (ils s'arr√™teront naturellement)
            pass
        
        self.normal_workers = new_count
        self.stats['dynamic_scaling_events'] += 1
    
    async def _scale_any_workers(self, new_count: int):
        """Ajuste le nombre de workers any"""
        if new_count > self.any_workers:
            # Ajouter des workers
            for i in range(self.any_workers, new_count):
                task = asyncio.create_task(self._any_worker_loop(f"any_worker_{i}"))
                self.any_worker_tasks.append(task)
        else:
            # R√©duire les workers (ils s'arr√™teront naturellement)
            pass
        
        self.any_workers = new_count
        self.stats['dynamic_scaling_events'] += 1
    
    async def _normal_worker_loop(self, worker_name: str):
        """Boucle de travail pour les workers de la pool normale avec scaling dynamique"""
        logger.info(f"Worker {worker_name} d√©marr√©")
        
        while self.normal_workers_running:
            try:
                # V√©rifier le scaling dynamique
                await self._dynamic_scaling_check()
                
                # Attendre une t√¢che avec timeout
                try:
                    task = await asyncio.wait_for(self.normal_pool.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                self.stats['normal_workers_active'] += 1
                self.stats['normal_pool_size'] = self.normal_pool.qsize()
                
                logger.debug(f"Worker {worker_name} traite la t√¢che {task.task_id} ({len(task.target_languages)} langues)")
                
                # Traiter la t√¢che
                start_time = time.time()
                await self._process_translation_task(task, worker_name)
                processing_time = time.time() - start_time
                
                # Mettre √† jour les stats de performance
                self.stats['avg_processing_time'] = (
                    (self.stats['avg_processing_time'] * (self.stats['tasks_processed']) + processing_time) 
                    / (self.stats['tasks_processed'] + 1)
                )
                
                self.stats['normal_workers_active'] -= 1
                self.stats['tasks_processed'] += 1
                
            except Exception as e:
                logger.error(f"Erreur dans le worker {worker_name}: {e}")
                self.stats['tasks_failed'] += 1
                if self.stats['normal_workers_active'] > 0:
                    self.stats['normal_workers_active'] -= 1
        
        logger.info(f"Worker {worker_name} arr√™t√©")
    
    async def _any_worker_loop(self, worker_name: str):
        """Boucle de travail pour les workers de la pool 'any' avec scaling dynamique"""
        logger.info(f"Worker {worker_name} d√©marr√©")
        
        while self.any_workers_running:
            try:
                # V√©rifier le scaling dynamique
                await self._dynamic_scaling_check()
                
                # Attendre une t√¢che avec timeout
                try:
                    task = await asyncio.wait_for(self.any_pool.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                self.stats['any_workers_active'] += 1
                self.stats['any_pool_size'] = self.any_pool.qsize()
                
                logger.debug(f"Worker {worker_name} traite la t√¢che {task.task_id} ({len(task.target_languages)} langues)")
                
                # Traiter la t√¢che
                start_time = time.time()
                await self._process_translation_task(task, worker_name)
                processing_time = time.time() - start_time
                
                # Mettre √† jour les stats de performance
                self.stats['avg_processing_time'] = (
                    (self.stats['avg_processing_time'] * (self.stats['tasks_processed']) + processing_time) 
                    / (self.stats['tasks_processed'] + 1)
                )
                
                self.stats['any_workers_active'] -= 1
                self.stats['tasks_processed'] += 1
                
            except Exception as e:
                logger.error(f"Erreur dans le worker {worker_name}: {e}")
                self.stats['tasks_failed'] += 1
                if self.stats['any_workers_active'] > 0:
                    self.stats['any_workers_active'] -= 1
        
        logger.info(f"Worker {worker_name} arr√™t√©")
    
    async def _process_translation_task(self, task: TranslationTask, worker_name: str):
        """Traite une t√¢che de traduction avec traduction parall√®le"""
        try:
            # Lancer les traductions en parall√®le
            translation_tasks = []
            
            for target_language in task.target_languages:
                translation_task = asyncio.create_task(
                    self._translate_single_language(task, target_language, worker_name)
                )
                translation_tasks.append((target_language, translation_task))
            
            # Attendre toutes les traductions
            for target_language, translation_task in translation_tasks:
                try:
                    result = await translation_task
                    # Ajouter le type de pool au r√©sultat
                    result['poolType'] = 'any' if task.conversation_id == 'any' else 'normal'
                    result['created_at'] = task.created_at
                    # Publier le r√©sultat via PUB
                    await self._publish_translation_result(task.task_id, result, target_language)
                    self.stats['translations_completed'] += 1
                    
                except Exception as e:
                    logger.error(f"Erreur de traduction pour {target_language} dans {task.task_id}: {e}")
                    # Publier un r√©sultat d'erreur
                    error_result = self._create_error_result(task, target_language, str(e))
                    await self._publish_translation_result(task.task_id, error_result, target_language)
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la t√¢che {task.task_id}: {e}")
            self.stats['tasks_failed'] += 1
    
    async def _translate_single_language(self, task: TranslationTask, target_language: str, worker_name: str):
        """Traduit un texte vers une langue cible sp√©cifique"""
        start_time = time.time()
        
        logger.info(f"üîÑ [TRANSLATOR] D√©but traduction: worker={worker_name}, texte='{task.text[:30]}...', source={task.source_language}, target={target_language}")
        
        try:
            # Utiliser le service de traduction partag√©
            if self.translation_service:
                logger.info(f"üîß [TRANSLATOR] Avant appel ML service: {worker_name}")
                # Effectuer la vraie traduction avec le service ML unifi√©
                result = await self.translation_service.translate(
                    text=task.text,
                    source_language=task.source_language,
                    target_language=target_language,
                    model_type=task.model_type,
                    source_channel='zmq'  # Identifier le canal source
                )
                logger.info(f"üîß [TRANSLATOR] Apr√®s appel ML service: {worker_name}, r√©sultat: {type(result)}")
                
                processing_time = time.time() - start_time
                
                # V√©rifier si le r√©sultat est None ou invalide
                if result is None:
                    logger.error(f"‚ùå [TRANSLATOR] Service ML a retourn√© None pour {worker_name}")
                    raise Exception("Service de traduction a retourn√© None")
                
                # V√©rifier que le r√©sultat contient les cl√©s attendues
                if not isinstance(result, dict) or 'translated_text' not in result:
                    logger.error(f"‚ùå [TRANSLATOR] R√©sultat invalide pour {worker_name}: {result}")
                    raise Exception(f"R√©sultat de traduction invalide: {result}")
                
                logger.info(f"‚úÖ [TRANSLATOR] Traduction termin√©e: worker={worker_name}, '{task.text[:30]}...' ‚Üí '{result['translated_text'][:30]}...' ({processing_time:.3f}s)")
                
                return {
                    'messageId': task.message_id,
                    'translatedText': result['translated_text'],
                    'sourceLanguage': result.get('detected_language', task.source_language),
                    'targetLanguage': target_language,
                    'confidenceScore': result.get('confidence', 0.95),
                    'processingTime': processing_time,
                    'modelType': task.model_type,
                    'workerName': worker_name
                }
            else:
                # Fallback si pas de service de traduction
                translated_text = f"[{target_language.upper()}] {task.text}"
                processing_time = time.time() - start_time
                
                return {
                    'messageId': task.message_id,
                    'translatedText': translated_text,
                    'sourceLanguage': task.source_language,
                    'targetLanguage': target_language,
                    'confidenceScore': 0.1,
                    'processingTime': processing_time,
                    'modelType': 'fallback',
                    'workerName': worker_name,
                    'error': 'No translation service available'
                }
            
        except Exception as e:
            logger.error(f"Erreur de traduction dans {worker_name}: {e}")
            # Fallback en cas d'erreur
            translated_text = f"[{target_language.upper()}] {task.text}"
            processing_time = time.time() - start_time
            
            return {
                'messageId': task.message_id,
                'translatedText': translated_text,
                'sourceLanguage': task.source_language,
                'targetLanguage': target_language,
                'confidenceScore': 0.1,
                'processingTime': processing_time,
                'modelType': 'fallback',
                'workerName': worker_name,
                'error': str(e)
            }
    
    def _create_error_result(self, task: TranslationTask, target_language: str, error_message: str):
        """Cr√©e un r√©sultat d'erreur pour une traduction √©chou√©e"""
        return {
            'messageId': task.message_id,
            'translatedText': f"[ERREUR: {error_message}]",
            'sourceLanguage': task.source_language,
            'targetLanguage': target_language,
            'confidenceScore': 0.0,
            'processingTime': 0.0,
            'modelType': task.model_type,
            'error': error_message
        }
    
    async def _publish_translation_result(self, task_id: str, result: dict, target_language: str):
        """Publie un r√©sultat de traduction via PUB"""
        try:
            # Cette m√©thode sera appel√©e par le serveur ZMQ principal
            # Le r√©sultat sera publi√© via le socket PUB
            # Note: Cette m√©thode sera remplac√©e par le serveur ZMQ principal
            pass
        except Exception as e:
            logger.error(f"Erreur lors de la publication du r√©sultat {task_id}: {e}")
    
    def get_stats(self) -> dict:
        """Retourne les statistiques actuelles"""
        return {
            **self.stats,
            'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
            'uptime_seconds': time.time() - getattr(self, '_start_time', time.time())
        }

class ZMQTranslationServer:
    """Serveur ZMQ pour la traduction avec architecture PUB/SUB"""
    
    def __init__(self, 
                 host: str = "0.0.0.0",
                 gateway_push_port: int = 5555,  # Port o√π Translator PULL bind (Gateway PUSH connect ici)
                 gateway_sub_port: int = 5558,   # Port o√π Translator PUB bind (Gateway SUB connect ici)
                 normal_pool_size: int = 10000,
                 any_pool_size: int = 10000,
                 normal_workers: int = 3,
                 any_workers: int = 2,
                 translation_service=None):
        
        self.host = host
        self.gateway_push_port = gateway_push_port  # Port pour PULL (recevoir commandes)
        self.gateway_sub_port = gateway_sub_port    # Port pour PUB (envoyer r√©ponses)
        self.context = zmq.asyncio.Context()
        
        # Sockets
        self.pull_socket = None  # PULL pour recevoir les commandes de traduction
        self.pub_socket = None   # PUB pour publier les r√©sultats (inchang√©)
        
        # Pool manager
        self.pool_manager = TranslationPoolManager(
            normal_pool_size=normal_pool_size,
            any_pool_size=any_pool_size,
            normal_workers=normal_workers,
            any_workers=any_workers,
            translation_service=translation_service
        )
        
        # Remplacer la m√©thode de publication du pool manager
        self.pool_manager._publish_translation_result = self._publish_translation_result
        
        # √âtat du serveur
        self.running = False
        self.worker_tasks = []
        
        logger.info(f"ZMQTranslationServer initialis√©: Gateway PUSH {host}:{gateway_push_port} (PULL bind)")
        logger.info(f"ZMQTranslationServer initialis√©: Gateway SUB {host}:{gateway_sub_port} (PUB bind)")

    async def initialize(self):
        """Initialise les sockets ZMQ avec architecture PUSH/PULL + PUB/SUB"""
        try:
            # Socket PULL pour recevoir les commandes du Gateway (remplace SUB)
            self.pull_socket = self.context.socket(zmq.PULL)
            self.pull_socket.bind(f"tcp://{self.host}:{self.gateway_push_port}")
            
            # Socket PUB pour publier les r√©sultats vers le Gateway (inchang√©)
            self.pub_socket = self.context.socket(zmq.PUB)
            self.pub_socket.bind(f"tcp://{self.host}:{self.gateway_sub_port}")
            
            # Petit d√©lai pour √©tablir les connexions ZMQ
            await asyncio.sleep(0.1)
            
            # D√©marrer les workers
            self.worker_tasks = await self.pool_manager.start_workers()
            
            logger.info("ZMQTranslationServer initialis√© avec succ√®s")
            logger.info(f"üîå Socket PULL li√© au port: {self.host}:{self.gateway_push_port}")
            logger.info(f"üîå Socket PUB li√© au port: {self.host}:{self.gateway_sub_port}")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation: {e}")
            raise
    
    async def start(self):
        """D√©marre le serveur"""
        if not self.pull_socket or not self.pub_socket:
            await self.initialize()
        
        self.running = True
        logger.info("ZMQTranslationServer d√©marr√©")
        logger.info(f"[TRANSLATOR] üîß √âtat du serveur: running={self.running}")
        logger.info(f"üîß Socket PULL li√©: {self.pull_socket is not None}")
        logger.info(f"üîß Socket PUB li√©: {self.pub_socket is not None}")
        
        try:
            while self.running:
                try:
                    # LOG D√âTAILL√â DES OBJETS AVANT COMMUNICATION
                    # DEBUG: Logs r√©duits de 60% - Suppression des v√©rifications d√©taill√©es
                    logger.info("üéß En attente de commandes ZMQ...")
                    # Recevoir une commande de traduction via PULL
                    message = await self.pull_socket.recv()
                    
                                    # DEBUG: Logs r√©duits de 60% - Suppression des v√©rifications d√©taill√©es
                    
                    await self._handle_translation_request(message)
                    
                except zmq.ZMQError as e:
                    if self.running:
                        logger.error(f"Erreur ZMQ: {e}")
                    break
                except Exception as e:
                    logger.error(f"Erreur inattendue: {e}")
                    import traceback
                    traceback.print_exc()
                    
        except KeyboardInterrupt:
            logger.info("Arr√™t demand√© par l'utilisateur")
        finally:
            await self.stop()
    
    async def _handle_translation_request(self, message: bytes):
        """Traite une requ√™te de traduction re√ßue via SUB"""
        try:
            request_data = json.loads(message.decode('utf-8'))
            
            logger.info(f"üì• [TRANSLATOR] Commande PULL re√ßue: {request_data}")
            
            # V√©rifier si c'est un message de ping
            if request_data.get('type') == 'ping':
                logger.info(f"üèì [TRANSLATOR] Ping re√ßu, timestamp: {request_data.get('timestamp')}")
                # R√©pondre au ping via PUB
                ping_response = {
                    'type': 'pong',
                    'timestamp': time.time(),
                    'translator_status': 'alive',
                    'translator_port_pub': self.gateway_sub_port,
                    'translator_port_pull': self.gateway_push_port
                }
                if self.pub_socket:
                    await self.pub_socket.send(json.dumps(ping_response).encode('utf-8'))
                    logger.info(f"üèì [TRANSLATOR] Pong envoy√© via port {self.gateway_sub_port}")
                else:
                    logger.error(f"‚ùå [TRANSLATOR] Socket PUB non disponible pour pong (port {self.gateway_sub_port})")
                return
            
            # V√©rifier que c'est une requ√™te de traduction valide
            if not request_data.get('text') or not request_data.get('targetLanguages'):
                logger.warning(f"‚ö†Ô∏è [TRANSLATOR] Requ√™te invalide re√ßue: {request_data}")
                return
            
            # Cr√©er la t√¢che de traduction
            task = TranslationTask(
                task_id=str(uuid.uuid4()),
                message_id=request_data.get('messageId'),
                text=request_data.get('text'),
                source_language=request_data.get('sourceLanguage', 'fr'),
                target_languages=request_data.get('targetLanguages', []),
                conversation_id=request_data.get('conversationId', 'unknown'),
                model_type=request_data.get('modelType', 'basic')
            )
            
            logger.info(f"üîß [TRANSLATOR] T√¢che cr√©√©e: {task.task_id} pour {task.conversation_id} ({len(task.target_languages)} langues)")
            logger.info(f"üìù [TRANSLATOR] D√©tails: texte='{task.text[:50]}...', source={task.source_language}, target={task.target_languages}, mod√®le={task.model_type}")
            
            # Enfiler la t√¢che dans la pool appropri√©e
            success = await self.pool_manager.enqueue_task(task)
            
            if not success:
                # Pool pleine, publier un message d'erreur vers la gateway
                error_message = {
                    'type': 'translation_error',
                    'taskId': task.task_id,
                    'messageId': task.message_id,
                    'error': 'translation pool full',
                    'conversationId': task.conversation_id
                }
                # Utiliser le socket PUB configur√© pour envoyer l'erreur √† la gateway
                if self.pub_socket:
                    await self.pub_socket.send(json.dumps(error_message).encode('utf-8'))
                    logger.warning(f"Pool pleine, rejet de la t√¢che {task.task_id}")
                else:
                    logger.error("‚ùå Socket PUB non initialis√© pour envoyer l'erreur")
            
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de d√©codage JSON: {e}")
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la requ√™te: {e}")
    
    async def _publish_translation_result(self, task_id: str, result: dict, target_language: str):
        """Publie un r√©sultat de traduction via PUB vers la gateway avec informations techniques compl√®tes"""
        try:
            # DEBUG: Logs r√©duits de 60% - Suppression des v√©rifications d√©taill√©es
            
            # R√©cup√©rer les informations techniques du syst√®me
            import socket
            import uuid
            
            # Calculer le temps d'attente en queue
            queue_time = time.time() - result.get('created_at', time.time())
            
            # R√©cup√©rer les m√©triques syst√®me
            memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            cpu_usage = psutil.Process().cpu_percent()
            # Attendre un peu pour avoir une mesure CPU valide
            await asyncio.sleep(0.1)
            cpu_usage = psutil.Process().cpu_percent()
            
            # Enrichir le r√©sultat avec toutes les informations techniques
            enriched_result = {
                # Informations applicatives existantes
                'messageId': result.get('messageId'),
                'translatedText': result.get('translatedText'),
                'sourceLanguage': result.get('sourceLanguage'),
                'targetLanguage': result.get('targetLanguage'),
                'confidenceScore': result.get('confidenceScore', 0.0),
                'processingTime': result.get('processingTime', 0.0),
                'modelType': result.get('modelType', 'basic'),
                'workerName': result.get('workerName', 'unknown'),
                
                # NOUVELLES INFORMATIONS TECHNIQUES
                'translatorModel': result.get('modelType', 'basic'),  # Mod√®le ML utilis√©
                'workerId': result.get('workerName', 'unknown'),      # Worker qui a trait√©
                'poolType': result.get('poolType', 'normal'),         # Pool utilis√©e (normal/any)
                'translationTime': result.get('processingTime', 0.0), # Temps de traduction
                'queueTime': queue_time,                              # Temps d'attente en queue
                'memoryUsage': memory_usage,                          # Usage m√©moire (MB)
                'cpuUsage': cpu_usage,                                # Usage CPU (%)
                'timestamp': time.time(),
                'version': '1.0.0'  # Version du Translator
            }
            
            # Cr√©er le message enrichi
            message = {
                'type': 'translation_completed',
                'taskId': task_id,
                'result': enriched_result,
                'targetLanguage': target_language,
                'timestamp': time.time(),
                # M√âTADONN√âES TECHNIQUES
                'metadata': {
                    'translatorVersion': '1.0.0',
                    'modelVersion': result.get('modelType', 'basic'),
                    'processingNode': socket.gethostname(),
                    'sessionId': str(uuid.uuid4()),
                    'requestId': task_id,
                    'protocol': 'ZMQ_PUB_SUB',
                    'encoding': 'UTF-8'
                }
            }
            
            # DEBUG: Logs r√©duits de 60% - Suppression des d√©tails techniques
            
            # Utiliser le socket PUB configur√© pour envoyer √† la gateway
            if self.pub_socket:
                # DEBUG: Logs r√©duits de 60% - Suppression des v√©rifications d'envoi
                
                await self.pub_socket.send(json.dumps(message).encode('utf-8'))
                
                # DEBUG: Logs r√©duits de 60% - Suppression des v√©rifications post-envoi
                logger.info(f"üì§ [TRANSLATOR] R√©sultat envoy√©: {task_id} -> {target_language}")
            else:
                logger.error("‚ùå Socket PUB non initialis√©")
            
        except Exception as e:
            logger.error(f"Erreur lors de la publication du r√©sultat enrichi: {e}")
            import traceback
            traceback.print_exc()
    
    async def stop(self):
        """Arr√™te le serveur"""
        self.running = False
        
        # Arr√™ter les workers
        await self.pool_manager.stop_workers()
        
        # Attendre que tous les workers se terminent
        if self.worker_tasks:
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)
        
        # Fermer les sockets
        if self.pull_socket:
            self.pull_socket.close()
        if self.pub_socket:
            self.pub_socket.close()
        
        logger.info("ZMQTranslationServer arr√™t√©")
    
    def get_stats(self) -> dict:
        """Retourne les statistiques du serveur"""
        pool_stats = self.pool_manager.get_stats()
        
        return {
            'server_status': 'running' if self.running else 'stopped',
            'gateway_push_port': self.gateway_push_port,
            'gateway_sub_port': self.gateway_sub_port,
            'normal_workers': self.pool_manager.normal_workers,
            'any_workers': self.pool_manager.any_workers,
            **pool_stats
        }
    
    async def health_check(self) -> dict:
        """V√©rification de sant√© du serveur"""
        try:
            stats = self.get_stats()
            return {
                'status': 'healthy',
                'running': self.running,
                'stats': stats
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

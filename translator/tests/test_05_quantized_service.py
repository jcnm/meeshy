#!/usr/bin/env python3
"""
Test 05 - Service de traduction quantifi√©
Niveau: Expert - Test du service avec quantification
"""

import sys
import os
import logging
import asyncio

# Ajouter le r√©pertoire src au path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from services.quantized_ml_service import QuantizedMLService
    from utils.model_utils import create_model_manager
    from config.settings import get_settings
    SERVICE_AVAILABLE = True
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.warning(f"‚ö†Ô∏è Service non disponible: {e}")
    SERVICE_AVAILABLE = False

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_quantized_service_creation():
    """Test de cr√©ation du service quantifi√©"""
    logger.info("üß™ Test 05.1: Cr√©ation du service quantifi√©")
    
    if not SERVICE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Service non disponible, test ignor√©")
        return True
    
    try:
        # Tester diff√©rents niveaux de quantification
        quantization_levels = ["float16", "float32"]
        
        for level in quantization_levels:
            service = QuantizedMLService(
                model_type="basic", 
                quantization_level=level,
                max_workers=2
            )
            
            assert service.quantization_level == level
            assert service.model_type == "basic"
            assert service.max_workers == 2
            
            logger.info(f"‚úÖ Service quantifi√© cr√©√© avec {level}")
        
        logger.info("‚úÖ Tous les services quantifi√©s cr√©√©s avec succ√®s")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation service quantifi√©: {e}")
        return False

async def test_model_sharing():
    """Test du partage de mod√®les"""
    logger.info("üß™ Test 05.2: Partage de mod√®les")
    
    if not SERVICE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Service non disponible, test ignor√©")
        return True
    
    try:
        # Cr√©er un service avec tous les mod√®les
        service = QuantizedMLService(model_type="all", quantization_level="float16")
        
        # V√©rifier la configuration des mod√®les
        model_configs = service.model_configs
        
        # Identifier les mod√®les partag√©s
        model_name_to_types = {}
        for model_type, config in model_configs.items():
            model_name = config['model_name']
            if model_name not in model_name_to_types:
                model_name_to_types[model_name] = []
            model_name_to_types[model_name].append(model_type)
        
        # Afficher les mod√®les partag√©s
        shared_models = {name: types for name, types in model_name_to_types.items() if len(types) > 1}
        
        if shared_models:
            logger.info("üìã Mod√®les partag√©s d√©tect√©s:")
            for model_name, types in shared_models.items():
                logger.info(f"  - {model_name}: {types}")
        else:
            logger.info("üìã Aucun mod√®le partag√© d√©tect√©")
        
        logger.info("‚úÖ Analyse du partage de mod√®les r√©ussie")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur partage mod√®les: {e}")
        return False

async def test_fallback_system():
    """Test du syst√®me de fallback"""
    logger.info("üß™ Test 05.3: Syst√®me de fallback")
    
    if not SERVICE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Service non disponible, test ignor√©")
        return True
    
    try:
        # Tester le fallback avec diff√©rents types de mod√®les
        fallback_order = ['premium', 'medium', 'basic']
        
        for model_type in fallback_order:
            service = QuantizedMLService(model_type=model_type, quantization_level="float16")
            
            # V√©rifier que le service est configur√© correctement
            assert service.model_type == model_type
            
            logger.info(f"‚úÖ Service configur√© pour {model_type}")
        
        logger.info("‚úÖ Syst√®me de fallback test√© avec succ√®s")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur syst√®me fallback: {e}")
        return False

async def test_translation_quality():
    """Test de la qualit√© de traduction"""
    logger.info("üß™ Test 05.4: Qualit√© de traduction")
    
    if not SERVICE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Service non disponible, test ignor√©")
        return True
    
    try:
        # Cr√©er le service
        service = QuantizedMLService(model_type="basic", quantization_level="float16")
        
        # V√©rifier les mod√®les disponibles
        models_status = service.get_models_status()
        local_models = [name for name, status in models_status.items() if status['local']]
        
        if not local_models:
            logger.warning("‚ö†Ô∏è Aucun mod√®le local disponible pour le test de qualit√©")
            return True
        
        # Initialiser le service
        init_success = await service.initialize()
        if not init_success:
            logger.error("‚ùå Impossible d'initialiser le service pour le test de qualit√©")
            return False
        
        # Tests de traduction avec diff√©rents textes
        test_cases = [
            ("Hello, how are you?", "en", "fr"),
            ("Bonjour, comment allez-vous?", "fr", "en"),
            ("The weather is nice today.", "en", "es"),
        ]
        
        successful_translations = 0
        
        for original_text, source_lang, target_lang in test_cases:
            try:
                result = await service.translate(original_text, source_lang, target_lang, "basic")
                
                if result and 'translated_text' in result:
                    translated = result['translated_text']
                    logger.info(f"‚úÖ Traduction {source_lang}‚Üí{target_lang}:")
                    logger.info(f"  - Original: {original_text}")
                    logger.info(f"  - Traduit: {translated}")
                    successful_translations += 1
                else:
                    logger.warning(f"‚ö†Ô∏è √âchec traduction {source_lang}‚Üí{target_lang}")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur traduction {source_lang}‚Üí{target_lang}: {e}")
        
        # Nettoyer le service
        await service.cleanup()
        
        # √âvaluer la qualit√©
        quality_score = successful_translations / len(test_cases)
        logger.info(f"üìä Score de qualit√©: {quality_score:.1%} ({successful_translations}/{len(test_cases)})")
        
        # Le test r√©ussit si au moins 50% des traductions fonctionnent
        success = quality_score >= 0.5
        if success:
            logger.info("‚úÖ Test de qualit√© de traduction r√©ussi")
        else:
            logger.warning("‚ö†Ô∏è Qualit√© de traduction insuffisante")
        
        return success
        
    except Exception as e:
        logger.error(f"‚ùå Erreur test qualit√©: {e}")
        return False

async def test_performance_metrics():
    """Test des m√©triques de performance"""
    logger.info("üß™ Test 05.5: M√©triques de performance")
    
    if not SERVICE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Service non disponible, test ignor√©")
        return True
    
    try:
        # Cr√©er le service
        service = QuantizedMLService(model_type="basic", quantization_level="float16")
        
        # Initialiser le service
        init_success = await service.initialize()
        if not init_success:
            logger.error("‚ùå Impossible d'initialiser le service pour les m√©triques")
            return False
        
        # Obtenir les statistiques
        stats = service.get_stats()
        
        logger.info("üìä M√©triques de performance:")
        for key, value in stats.items():
            logger.info(f"  - {key}: {value}")
        
        # V√©rifier les m√©triques importantes
        important_metrics = [
            'models_loaded',
            'quantization_level',
            'translations_count',
            'memory_usage_mb'
        ]
        
        for metric in important_metrics:
            if metric in stats:
                logger.info(f"‚úÖ M√©trique {metric}: {stats[metric]}")
            else:
                logger.warning(f"‚ö†Ô∏è M√©trique {metric} manquante")
        
        # Nettoyer le service
        await service.cleanup()
        
        logger.info("‚úÖ M√©triques de performance r√©cup√©r√©es avec succ√®s")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur m√©triques performance: {e}")
        return False

async def run_all_tests():
    """Ex√©cute tous les tests du service quantifi√©"""
    logger.info("üöÄ D√©marrage des tests du service quantifi√© (Test 05)")
    logger.info("=" * 50)
    
    tests = [
        ("Cr√©ation service quantifi√©", test_quantized_service_creation),
        ("Partage de mod√®les", test_model_sharing),
        ("Syst√®me de fallback", test_fallback_system),
        ("Qualit√© de traduction", test_translation_quality),
        ("M√©triques de performance", test_performance_metrics),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\nüìã {test_name}...")
        
        # Ex√©cuter le test (synchrone ou asynchrone)
        if asyncio.iscoroutinefunction(test_func):
            result = await test_func()
        else:
            result = test_func()
        
        if result:
            passed += 1
            logger.info(f"‚úÖ {test_name} - R√âUSSI")
        else:
            logger.error(f"‚ùå {test_name} - √âCHOU√â")
    
    logger.info("\n" + "=" * 50)
    logger.info(f"üìä R√©sultats Test 05: {passed}/{total} tests r√©ussis")
    
    if passed == total:
        logger.info("üéâ Tous les tests du service quantifi√© ont r√©ussi!")
        return True
    else:
        logger.error(f"üí• {total - passed} test(s) ont √©chou√©")
        return False

if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)

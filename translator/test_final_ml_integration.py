#!/usr/bin/env python3
"""
Test d'intÃ©gration final du service ML unifiÃ©
VÃ©rifie que les vrais modÃ¨les T5 et NLLB sont utilisÃ©s
"""

import asyncio
import sys
import os
from pathlib import Path

# Ajouter src au path et charger .env
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… Variables d'environnement .env chargÃ©es")
except ImportError:
    print("âš ï¸ python-dotenv non disponible")

from services.unified_ml_service import get_unified_ml_service
from services.zmq_server import ZMQTranslationServer

async def test_ml_integration():
    """Test complet du service ML unifiÃ©"""
    print("ğŸ§ª TEST D'INTÃ‰GRATION ML UNIFIÃ‰")
    print("=" * 50)
    
    # 1. TEST DU SERVICE ML SEUL
    print("\nğŸ“š 1. Test du service ML unifiÃ© seul:")
    service = get_unified_ml_service(max_workers=2)
    
    success = await service.initialize()
    print(f"   InitialisÃ©: {success}")
    
    if success:
        # Test T5-small
        print("\n   ğŸ”§ Test T5-small (basic):")
        result_t5 = await service.translate(
            text="Hello world test",
            source_language="en",
            target_language="fr",
            model_type="basic",
            source_channel="test"
        )
        print(f"   ENâ†’FR: \"{result_t5.get('translated_text', 'N/A')}\"")
        print(f"   ModÃ¨le: {result_t5.get('model_used', 'N/A')}")
        
        # Test NLLB
        print("\n   ğŸ”§ Test NLLB-600M (medium):")
        result_nllb = await service.translate(
            text="Bonjour le monde",
            source_language="fr",
            target_language="en",
            model_type="medium",
            source_channel="test"
        )
        print(f"   FRâ†’EN: \"{result_nllb.get('translated_text', 'N/A')}\"")
        print(f"   ModÃ¨le: {result_nllb.get('model_used', 'N/A')}")
        
        # Stats
        stats = await service.get_stats()
        print(f"\n   ğŸ“Š Stats: {stats['translations_count']} traductions")
        print(f"   ğŸ“ ModÃ¨les: {list(stats['models_loaded'].keys())}")
        
    # 2. TEST ZMQ SERVER AVEC SERVICE ML
    print("\n\nğŸ”— 2. Test ZMQ Server avec service ML:")
    
    try:
        # CrÃ©er serveur ZMQ avec le service ML unifiÃ©
        zmq_server = ZMQTranslationServer(
            host="0.0.0.0",
            gateway_pub_port=5557,
            gateway_sub_port=5555,
            normal_workers=2,
            any_workers=1,
            translation_service=service  # Service ML unifiÃ©
        )
        
        print("   âœ… ZMQ Server crÃ©Ã© avec service ML unifiÃ©")
        print("   ğŸ¯ Le serveur ZMQ utilise maintenant les vrais modÃ¨les ML")
        
        # VÃ©rifier la configuration
        if zmq_server.translation_service:
            print(f"   ğŸ“š Service attachÃ©: {type(zmq_server.translation_service).__name__}")
            print(f"   ğŸ¤– Est service unifiÃ©: {hasattr(zmq_server.translation_service, 'models')}")
        
    except Exception as e:
        print(f"   âŒ Erreur ZMQ Server: {e}")
    
    print("\n" + "=" * 50)
    print("âœ… TEST D'INTÃ‰GRATION TERMINÃ‰")
    print("ğŸ¯ Le service ML unifiÃ© est prÃªt avec vrais modÃ¨les")
    print("ğŸ“Š ModÃ¨les disponibles:")
    print("   - basic: T5-small (local)")
    print("   - medium: NLLB-600M (local)")  
    print("   - premium: NLLB-1.3B (local)")

if __name__ == "__main__":
    asyncio.run(test_ml_integration())

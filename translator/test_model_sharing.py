#!/usr/bin/env python3
"""
Script de test pour v√©rifier le syst√®me de partage de mod√®les
Teste l'optimisation m√©moire quand plusieurs types utilisent le m√™me mod√®le
"""

import asyncio
import logging
import sys
from pathlib import Path

# Ajouter le r√©pertoire src au path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from services.quantized_ml_service import QuantizedMLService

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

async def test_model_sharing():
    """Teste le syst√®me de partage de mod√®les"""
    logger.info("üß™ Test du syst√®me de partage de mod√®les")
    
    # Configuration avec mod√®les partag√©s
    # Simuler une configuration o√π basic et medium utilisent le m√™me mod√®le
    service = QuantizedMLService("all", "float16", max_workers=2)
    
    # Modifier la configuration pour simuler des mod√®les partag√©s
    service.model_configs['basic']['model_name'] = 'facebook/nllb-200-distilled-600M'
    service.model_configs['medium']['model_name'] = 'facebook/nllb-200-distilled-600M'
    service.model_configs['premium']['model_name'] = 'facebook/nllb-200-distilled-1.3B'
    
    logger.info("üîß Configuration de test:")
    for model_type, config in service.model_configs.items():
        logger.info(f"  {model_type}: {config['model_name']}")
    
    try:
        # Initialiser le service
        initialized = await service.initialize()
        
        if initialized:
            # Obtenir les statistiques
            stats = service.get_stats()
            
            logger.info("\nüìä Statistiques de partage:")
            logger.info(f"  Mod√®les partag√©s: {stats['shared_models_count']}")
            logger.info(f"  Types de mod√®les: {stats['total_model_types']}")
            logger.info(f"  Mod√®les uniques charg√©s: {stats['unique_models_loaded']}")
            logger.info(f"  Mod√®les √©conomis√©s: {stats['models_saved']}")
            logger.info(f"  M√©moire √©conomis√©e (estim√©e): {stats['estimated_memory_saved_mb']:.1f} MB")
            
            # Afficher les d√©tails des mod√®les partag√©s
            if stats['shared_models_info']:
                logger.info("\nüîÑ Mod√®les partag√©s:")
                for model_name, info in stats['shared_models_info'].items():
                    logger.info(f"  {model_name}: utilis√© par {info['users']}")
            
            # Tester les traductions avec diff√©rents types
            test_text = "Hello, how are you?"
            
            logger.info("\nüîÑ Tests de traduction:")
            for model_type in ['basic', 'medium', 'premium']:
                if model_type in service.models:
                    result = await service.translate(test_text, "en", "fr", model_type)
                    logger.info(f"  {model_type}: '{test_text}' -> '{result['translated_text']}'")
                    logger.info(f"    Mod√®le utilis√©: {result['model_used']}")
                else:
                    logger.warning(f"  {model_type}: mod√®le non disponible")
            
            # V√©rifier que les mod√®les partag√©s pointent vers la m√™me instance
            if 'basic' in service.models and 'medium' in service.models:
                basic_model_id = id(service.models['basic'])
                medium_model_id = id(service.models['medium'])
                
                if basic_model_id == medium_model_id:
                    logger.info("‚úÖ Confirmation: basic et medium utilisent la m√™me instance de mod√®le")
                else:
                    logger.warning("‚ö†Ô∏è Erreur: basic et medium utilisent des instances diff√©rentes")
            
        else:
            logger.error("‚ùå √âchec de l'initialisation du service")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test: {e}")
    
    finally:
        if 'service' in locals():
            await service.cleanup()

async def test_no_sharing():
    """Teste le comportement sans partage de mod√®les"""
    logger.info("\nüß™ Test sans partage de mod√®les")
    
    # Configuration avec mod√®les diff√©rents
    service = QuantizedMLService("all", "float16", max_workers=2)
    
    # Modifier la configuration pour des mod√®les diff√©rents
    service.model_configs['basic']['model_name'] = 't5-small'
    service.model_configs['medium']['model_name'] = 'facebook/nllb-200-distilled-600M'
    service.model_configs['premium']['model_name'] = 'facebook/nllb-200-distilled-1.3B'
    
    logger.info("üîß Configuration de test (mod√®les diff√©rents):")
    for model_type, config in service.model_configs.items():
        logger.info(f"  {model_type}: {config['model_name']}")
    
    try:
        # Initialiser le service
        initialized = await service.initialize()
        
        if initialized:
            # Obtenir les statistiques
            stats = service.get_stats()
            
            logger.info("\nüìä Statistiques sans partage:")
            logger.info(f"  Mod√®les partag√©s: {stats['shared_models_count']}")
            logger.info(f"  Types de mod√®les: {stats['total_model_types']}")
            logger.info(f"  Mod√®les uniques charg√©s: {stats['unique_models_loaded']}")
            logger.info(f"  Mod√®les √©conomis√©s: {stats['models_saved']}")
            
            # V√©rifier que les mod√®les sont diff√©rents
            model_ids = set()
            for model_type in ['basic', 'medium', 'premium']:
                if model_type in service.models:
                    model_ids.add(id(service.models[model_type]))
            
            if len(model_ids) == 3:
                logger.info("‚úÖ Confirmation: tous les mod√®les sont des instances diff√©rentes")
            else:
                logger.warning(f"‚ö†Ô∏è Inattendu: {len(model_ids)} instances uniques pour 3 mod√®les")
            
        else:
            logger.error("‚ùå √âchec de l'initialisation du service")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test: {e}")
    
    finally:
        if 'service' in locals():
            await service.cleanup()

async def test_memory_optimization():
    """Teste l'optimisation m√©moire"""
    logger.info("\nüß™ Test d'optimisation m√©moire")
    
    # Configuration avec partage maximal
    service = QuantizedMLService("all", "float16", max_workers=2)
    
    # Tous les mod√®les utilisent le m√™me mod√®le
    service.model_configs['basic']['model_name'] = 'facebook/nllb-200-distilled-600M'
    service.model_configs['medium']['model_name'] = 'facebook/nllb-200-distilled-600M'
    service.model_configs['premium']['model_name'] = 'facebook/nllb-200-distilled-600M'
    
    logger.info("üîß Configuration avec partage maximal:")
    for model_type, config in service.model_configs.items():
        logger.info(f"  {model_type}: {config['model_name']}")
    
    try:
        # Initialiser le service
        initialized = await service.initialize()
        
        if initialized:
            # Obtenir les statistiques
            stats = service.get_stats()
            
            logger.info("\nüìä Optimisation m√©moire maximale:")
            logger.info(f"  Mod√®les partag√©s: {stats['shared_models_count']}")
            logger.info(f"  Types de mod√®les: {stats['total_model_types']}")
            logger.info(f"  Mod√®les uniques charg√©s: {stats['unique_models_loaded']}")
            logger.info(f"  Mod√®les √©conomis√©s: {stats['models_saved']}")
            logger.info(f"  M√©moire √©conomis√©e (estim√©e): {stats['estimated_memory_saved_mb']:.1f} MB")
            
            # V√©rifier que tous les mod√®les pointent vers la m√™me instance
            model_ids = set()
            for model_type in ['basic', 'medium', 'premium']:
                if model_type in service.models:
                    model_ids.add(id(service.models[model_type]))
            
            if len(model_ids) == 1:
                logger.info("‚úÖ Optimisation maximale: tous les mod√®les utilisent la m√™me instance")
            else:
                logger.warning(f"‚ö†Ô∏è Optimisation partielle: {len(model_ids)} instances pour 3 mod√®les")
            
        else:
            logger.error("‚ùå √âchec de l'initialisation du service")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test: {e}")
    
    finally:
        if 'service' in locals():
            await service.cleanup()

async def main():
    """Fonction principale de test"""
    logger.info("üöÄ D√©marrage des tests du syst√®me de partage de mod√®les")
    
    # Test 1: Partage de mod√®les
    await test_model_sharing()
    
    # Test 2: Sans partage
    await test_no_sharing()
    
    # Test 3: Optimisation m√©moire maximale
    await test_memory_optimization()
    
    logger.info("\n‚úÖ Tests du syst√®me de partage termin√©s")

if __name__ == "__main__":
    asyncio.run(main())

/**
 * Service de cache pour les mod√®les de traduction
 * G√®re le stockage local et la persistence des mod√®les TensorFlow.js
 */

export interface CachedModelInfo {
  family: string;
  variant: string;
  downloadDate: number;
  fileSize: number;
  version: string;
  checksum?: string;
}

export interface ModelCacheEntry {
  info: CachedModelInfo;
  modelBlob: Blob;
  tokenizerBlob?: Blob;
}

export class ModelCacheService {
  private static instance: ModelCacheService;
  private dbName = 'meeshy-models-cache';
  private dbVersion = 1;
  private db: IDBDatabase | null = null;

  static getInstance(): ModelCacheService {
    if (!ModelCacheService.instance) {
      ModelCacheService.instance = new ModelCacheService();
    }
    return ModelCacheService.instance;
  }

  private constructor() {
    this.initializeDatabase();
  }

  /**
   * Initialise la base de donn√©es IndexedDB pour le cache
   */
  private async initializeDatabase(): Promise<void> {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, this.dbVersion);

      request.onerror = () => {
        console.error('Erreur lors de l\'ouverture de la base de donn√©es de cache');
        reject(request.error);
      };

      request.onsuccess = () => {
        this.db = request.result;
        console.log('‚úÖ Base de donn√©es de cache des mod√®les initialis√©e');
        resolve();
      };

      request.onupgradeneeded = (event) => {
        const db = (event.target as IDBOpenDBRequest).result;
        
        // Store pour les mod√®les
        if (!db.objectStoreNames.contains('models')) {
          const modelsStore = db.createObjectStore('models', { keyPath: 'id' });
          modelsStore.createIndex('family', 'info.family', { unique: false });
          modelsStore.createIndex('variant', 'info.variant', { unique: false });
          modelsStore.createIndex('downloadDate', 'info.downloadDate', { unique: false });
        }

        // Store pour les m√©tadonn√©es
        if (!db.objectStoreNames.contains('metadata')) {
          db.createObjectStore('metadata', { keyPath: 'key' });
        }
      };
    });
  }

  /**
   * G√©n√®re une cl√© unique pour un mod√®le
   */
  private getModelKey(family: string, variant: string): string {
    return `${family}-${variant}`;
  }

  /**
   * V√©rifie si un mod√®le est en cache
   */
  async isModelCached(family: string, variant: string): Promise<boolean> {
    if (!this.db) await this.initializeDatabase();
    if (!this.db) return false;

    return new Promise((resolve) => {
      const transaction = this.db!.transaction(['models'], 'readonly');
      const store = transaction.objectStore('models');
      const request = store.get(this.getModelKey(family, variant));

      request.onsuccess = () => {
        resolve(!!request.result);
      };

      request.onerror = () => {
        console.error('Erreur lors de la v√©rification du cache');
        resolve(false);
      };
    });
  }

  /**
   * R√©cup√®re un mod√®le depuis le cache
   */
  async getCachedModel(family: string, variant: string): Promise<ModelCacheEntry | null> {
    if (!this.db) await this.initializeDatabase();
    if (!this.db) return null;

    return new Promise((resolve) => {
      const transaction = this.db!.transaction(['models'], 'readonly');
      const store = transaction.objectStore('models');
      const request = store.get(this.getModelKey(family, variant));

      request.onsuccess = () => {
        if (request.result) {
          console.log(`‚úÖ Mod√®le ${family}-${variant} trouv√© dans le cache`);
          resolve(request.result as ModelCacheEntry);
        } else {
          resolve(null);
        }
      };

      request.onerror = () => {
        console.error('Erreur lors de la r√©cup√©ration du mod√®le depuis le cache');
        resolve(null);
      };
    });
  }

  /**
   * Met en cache un mod√®le t√©l√©charg√©
   */
  async cacheModel(
    family: string,
    variant: string,
    modelBlob: Blob,
    tokenizerBlob?: Blob,
    version: string = '1.0.0'
  ): Promise<boolean> {
    if (!this.db) await this.initializeDatabase();
    if (!this.db) return false;

    const info: CachedModelInfo = {
      family,
      variant,
      downloadDate: Date.now(),
      fileSize: modelBlob.size + (tokenizerBlob?.size || 0),
      version,
    };

    const cacheEntry: ModelCacheEntry & { id: string } = {
      id: this.getModelKey(family, variant),
      info,
      modelBlob,
      tokenizerBlob,
    };

    return new Promise((resolve) => {
      const transaction = this.db!.transaction(['models'], 'readwrite');
      const store = transaction.objectStore('models');
      const request = store.put(cacheEntry);

      request.onsuccess = () => {
        console.log(`‚úÖ Mod√®le ${family}-${variant} mis en cache (${Math.round(info.fileSize / 1024 / 1024)}MB)`);
        resolve(true);
      };

      request.onerror = () => {
        console.error('Erreur lors de la mise en cache du mod√®le');
        resolve(false);
      };
    });
  }

  /**
   * Supprime un mod√®le du cache
   */
  async removeModel(family: string, variant: string): Promise<boolean> {
    if (!this.db) await this.initializeDatabase();
    if (!this.db) return false;

    return new Promise((resolve) => {
      const transaction = this.db!.transaction(['models'], 'readwrite');
      const store = transaction.objectStore('models');
      const request = store.delete(this.getModelKey(family, variant));

      request.onsuccess = () => {
        console.log(`üóëÔ∏è Mod√®le ${family}-${variant} supprim√© du cache`);
        resolve(true);
      };

      request.onerror = () => {
        console.error('Erreur lors de la suppression du mod√®le');
        resolve(false);
      };
    });
  }

  /**
   * Obtient la liste de tous les mod√®les en cache
   */
  async getCachedModels(): Promise<CachedModelInfo[]> {
    if (!this.db) await this.initializeDatabase();
    if (!this.db) return [];

    return new Promise((resolve) => {
      const transaction = this.db!.transaction(['models'], 'readonly');
      const store = transaction.objectStore('models');
      const request = store.getAll();

      request.onsuccess = () => {
        const models = request.result.map((entry: ModelCacheEntry & { id: string }) => entry.info);
        resolve(models);
      };

      request.onerror = () => {
        console.error('Erreur lors de la r√©cup√©ration de la liste des mod√®les');
        resolve([]);
      };
    });
  }

  /**
   * Calcule l'espace total utilis√© par le cache
   */
  async getCacheSize(): Promise<number> {
    const models = await this.getCachedModels();
    return models.reduce((total, model) => total + model.fileSize, 0);
  }

  /**
   * Nettoie le cache en supprimant les anciens mod√®les
   */
  async cleanOldModels(maxAgeInDays: number = 30): Promise<void> {
    const models = await this.getCachedModels();
    const cutoffDate = Date.now() - (maxAgeInDays * 24 * 60 * 60 * 1000);

    for (const model of models) {
      if (model.downloadDate < cutoffDate) {
        await this.removeModel(model.family, model.variant);
      }
    }
  }

  /**
   * T√©l√©charge et met en cache un mod√®le
   */
  async downloadAndCacheModel(
    family: string,
    variant: string,
    modelUrl: string,
    tokenizerUrl?: string,
    onProgress?: (progress: number) => void
  ): Promise<boolean> {
    try {
      console.log(`‚¨áÔ∏è T√©l√©chargement du mod√®le ${family}-${variant}...`);

      // T√©l√©charger le mod√®le principal
      const modelResponse = await this.downloadWithProgress(modelUrl, (progress) => {
        onProgress?.(progress * 0.8); // 80% pour le mod√®le principal
      });

      if (!modelResponse.ok) {
        throw new Error(`Erreur de t√©l√©chargement du mod√®le: ${modelResponse.status}`);
      }

      const modelBlob = await modelResponse.blob();

      // T√©l√©charger le tokenizer si sp√©cifi√©
      let tokenizerBlob: Blob | undefined;
      if (tokenizerUrl) {
        const tokenizerResponse = await this.downloadWithProgress(tokenizerUrl, (progress) => {
          onProgress?.(80 + progress * 0.2); // 20% pour le tokenizer
        });

        if (tokenizerResponse.ok) {
          tokenizerBlob = await tokenizerResponse.blob();
        }
      }

      // Mettre en cache
      const success = await this.cacheModel(family, variant, modelBlob, tokenizerBlob);
      
      if (success) {
        onProgress?.(100);
        console.log(`‚úÖ Mod√®le ${family}-${variant} t√©l√©charg√© et mis en cache`);
      }

      return success;
    } catch (error) {
      console.error(`‚ùå Erreur lors du t√©l√©chargement du mod√®le ${family}-${variant}:`, error);
      return false;
    }
  }

  /**
   * T√©l√©charge un fichier avec suivi du progr√®s
   */
  private async downloadWithProgress(
    url: string,
    onProgress?: (progress: number) => void
  ): Promise<Response> {
    const response = await fetch(url);
    
    if (!response.ok || !response.body) {
      return response;
    }

    const reader = response.body.getReader();
    const contentLength = parseInt(response.headers.get('content-length') || '0');
    
    let receivedLength = 0;
    const chunks: Uint8Array[] = [];

    while (true) {
      const { done, value } = await reader.read();
      
      if (done) break;
      
      chunks.push(value);
      receivedLength += value.length;
      
      if (contentLength > 0 && onProgress) {
        onProgress((receivedLength / contentLength) * 100);
      }
    }

    // Reconstituer la r√©ponse
    const allChunks = new Uint8Array(receivedLength);
    let position = 0;
    for (const chunk of chunks) {
      allChunks.set(chunk, position);
      position += chunk.length;
    }

    return new Response(allChunks.buffer, {
      status: response.status,
      statusText: response.statusText,
      headers: response.headers,
    });
  }

  /**
   * Exporte les statistiques du cache
   */
  async getStats(): Promise<{
    totalModels: number;
    totalSize: number;
    oldestModel: Date | null;
    newestModel: Date | null;
  }> {
    const models = await this.getCachedModels();
    
    if (models.length === 0) {
      return {
        totalModels: 0,
        totalSize: 0,
        oldestModel: null,
        newestModel: null,
      };
    }

    const dates = models.map(m => m.downloadDate);
    
    return {
      totalModels: models.length,
      totalSize: models.reduce((sum, m) => sum + m.fileSize, 0),
      oldestModel: new Date(Math.min(...dates)),
      newestModel: new Date(Math.max(...dates)),
    };
  }
}

export const modelCache = ModelCacheService.getInstance();

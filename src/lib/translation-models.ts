import * as tf from '@tensorflow/tfjs';
import { 
  type TranslationModelType, 
  type ModelCost, 
  UNIFIED_TRANSLATION_MODELS as TRANSLATION_MODELS,
  getModelConfig,
  getModelsByFamily,
  getCompatibleModels,
  recommendModel
} from '@/lib/unified-model-config';

// Interface pour la configuration des mod√®les avec statistiques d'usage
export interface ModelConfig {
  modelType: TranslationModelType;
  displayName: string;
  family: 'MT5' | 'NLLB';
  size: string;
  parameters: string;
  maxTokens: number;
  complexity: 'simple' | 'intermediate' | 'complex' | 'advanced';
  languages: string[];
  modelUrl?: string;
  tokenizer?: string;
  cost: ModelCost;
  color: string;
  quality: 'basic' | 'good' | 'high' | 'excellent' | 'premium';
  usageStats?: {
    totalUsage: number;
    lastUsed: Date | null;
    averageInferenceTime: number;
    successRate: number;
  };
}

// Configuration compl√®te de tous les mod√®les support√©s
// Maintenant bas√©e sur UNIFIED_TRANSLATION_MODELS avec des ajouts sp√©cifiques
export const MODELS_CONFIG: Record<TranslationModelType, ModelConfig> = Object.keys(TRANSLATION_MODELS).reduce((acc, key) => {
  const modelType = key as TranslationModelType;
  const unifiedConfig = TRANSLATION_MODELS[modelType];
  
  acc[modelType] = {
    modelType,
    displayName: unifiedConfig.displayName,
    family: unifiedConfig.family,
    size: unifiedConfig.size,
    parameters: unifiedConfig.parameters,
    maxTokens: unifiedConfig.maxTokens,
    complexity: unifiedConfig.purpose === 'simple' ? 'simple' : 'complex',
    languages: unifiedConfig.family === 'MT5' ? 
      ['en', 'fr', 'es', 'de', 'it', 'pt', 'ru', 'ja', 'ko', 'zh'] :
      ['en', 'fr', 'es', 'de', 'it', 'pt', 'ru', 'ja', 'ko', 'zh', 'ar', 'hi', 'tr', 'pl', 'nl'],
    modelUrl: unifiedConfig.modelUrl,
    tokenizer: `${unifiedConfig.family.toLowerCase()}-${unifiedConfig.size.toLowerCase()}`,
    cost: unifiedConfig.cost,
    color: unifiedConfig.color,
    quality: unifiedConfig.quality,
    usageStats: {
      totalUsage: 0,
      lastUsed: null,
      averageInferenceTime: unifiedConfig.cost.inferenceTime,
      successRate: 0.95
    }
  };
  
  return acc;
}, {} as Record<TranslationModelType, ModelConfig>);

/**
 * Service de gestion des mod√®les de traduction
 * Utilise la configuration unifi√©e pour une source unique de v√©rit√©
 */
export class TranslationModels {
  private models = new Map<string, tf.GraphModel>();
  private loadingPromises = new Map<string, Promise<tf.GraphModel | null>>();
  private initializationAttempted = new Map<string, boolean>();

  /**
   * Charge un mod√®le de traduction
   */
  async loadModel(modelName: string): Promise<tf.GraphModel | null> {
    // Si le mod√®le est d√©j√† charg√©, le retourner
    const cachedModel = this.models.get(modelName);
    if (cachedModel) {
      return cachedModel;
    }

    // Si le mod√®le est en cours de chargement, attendre
    const loadingPromise = this.loadingPromises.get(modelName);
    if (loadingPromise) {
      return loadingPromise;
    }

    // √âviter les tentatives r√©p√©t√©es de chargement d'un mod√®le qui a √©chou√©
    if (this.initializationAttempted.get(modelName)) {
      console.log(`‚ö†Ô∏è Mod√®le ${modelName} d√©j√† tent√©, utilisation du fallback`);
      return null;
    }

    // Commencer le chargement du mod√®le
    const promise = this.loadModelFromPath(modelName);
    this.loadingPromises.set(modelName, promise);
    this.initializationAttempted.set(modelName, true);

    try {
      const model = await promise;
      if (model) {
        this.models.set(modelName, model);
      }
      this.loadingPromises.delete(modelName);
      
      if (model) {
        console.log(`‚úÖ Mod√®le ${modelName} charg√© avec succ√®s`);
      } else {
        console.log(`‚ö†Ô∏è Mod√®le ${modelName} non disponible, utilisation du fallback`);
      }
      
      return model;
    } catch (loadError) {
      this.loadingPromises.delete(modelName);
      console.error(`‚ùå Erreur lors du chargement du mod√®le ${modelName}:`, loadError);
      return null;
    }
  }

  /**
   * Charge le mod√®le depuis le syst√®me de fichiers ou URL
   */
  private async loadModelFromPath(modelName: string): Promise<tf.GraphModel | null> {
    const config = MODELS_CONFIG[modelName as TranslationModelType];
    if (!config) {
      throw new Error(`Configuration pour le mod√®le ${modelName} non trouv√©e`);
    }

    try {
      // V√©rifier d'abord en local
      const localPath = `/models/${modelName}/model.json`;
      let model: tf.GraphModel;
      
      try {
        model = await tf.loadGraphModel(localPath);
        console.log(`üìÅ Mod√®le ${modelName} charg√© depuis le cache local`);
        return model;
      } catch {
        console.log(`üìÇ Mod√®le ${modelName} non trouv√© en local, t√©l√©chargement depuis l'URL...`);
        
        // Fallback vers l'URL externe
        if (config.modelUrl) {
          model = await tf.loadGraphModel(config.modelUrl);
          console.log(`üåê Mod√®le ${modelName} t√©l√©charg√© depuis ${config.modelUrl}`);
          return model;
        } else {
          throw new Error(`Aucune URL de mod√®le disponible pour ${modelName}`);
        }
      }
    } catch (error) {
      console.error(`‚ùå Impossible de charger le mod√®le ${modelName}:`, error);
      return null;
    }
  }

  /**
   * Obtient le nom du mod√®le appropri√© pour un type TranslationModelType
   */
  getModelKey(modelType: TranslationModelType): string {
    const config = getModelConfig(modelType);
    return `${config.family.toLowerCase()}_${config.size.toLowerCase()}`;
  }

  /**
   * Convertit un nom de mod√®le vers TranslationModelType
   */
  getModelType(modelName: string): TranslationModelType {
    // Conversion du format ancien vers le nouveau
    const mapping: Record<string, TranslationModelType> = {
      'mt5': 'MT5_SMALL',
      'mt5_small': 'MT5_SMALL',
      'mt5_base': 'MT5_BASE',
      'mt5_large': 'MT5_LARGE',
      'mt5_xl': 'MT5_XL',
      'mt5_xxl': 'MT5_XXL',
      'nllb': 'NLLB_200M',
      'nllb_200m': 'NLLB_200M',
      'nllb_distilled_600m': 'NLLB_DISTILLED_600M',
      'nllb_distilled_1_3b': 'NLLB_DISTILLED_1_3B',
      'nllb_1_3b': 'NLLB_1_3B',
      'nllb_3_3b': 'NLLB_3_3B',
      'nllb_54b': 'NLLB_54B'
    };

    return mapping[modelName.toLowerCase()] || 'MT5_SMALL';
  }

  /**
   * V√©rifie si un mod√®le est disponible
   */
  isModelLoaded(modelName: string): boolean {
    return this.models.has(modelName);
  }

  /**
   * Obtient la liste des mod√®les charg√©s
   */
  getLoadedModels(): string[] {
    return Array.from(this.models.keys());
  }

  /**
   * Lib√®re un mod√®le de la m√©moire
   */
  unloadModel(modelName: string): boolean {
    const model = this.models.get(modelName);
    if (model) {
      model.dispose();
      this.models.delete(modelName);
      this.initializationAttempted.delete(modelName);
      console.log(`üóëÔ∏è Mod√®le ${modelName} d√©charg√© de la m√©moire`);
      return true;
    }
    return false;
  }

  /**
   * Lib√®re tous les mod√®les de la m√©moire
   */
  unloadAllModels(): void {
    for (const [modelName, model] of this.models.entries()) {
      model.dispose();
      console.log(`üóëÔ∏è Mod√®le ${modelName} d√©charg√©`);
    }
    this.models.clear();
    this.initializationAttempted.clear();
    this.loadingPromises.clear();
  }

  /**
   * Met √† jour les statistiques d'usage d'un mod√®le
   */
  updateUsageStats(modelType: TranslationModelType, inferenceTime: number, success: boolean): void {
    const config = MODELS_CONFIG[modelType];
    if (config && config.usageStats) {
      config.usageStats.totalUsage++;
      config.usageStats.lastUsed = new Date();
      
      // Moyenne mobile de temps d'inf√©rence
      const currentAvg = config.usageStats.averageInferenceTime;
      const totalUsage = config.usageStats.totalUsage;
      config.usageStats.averageInferenceTime = 
        (currentAvg * (totalUsage - 1) + inferenceTime) / totalUsage;
      
      // Taux de succ√®s avec moyenne mobile
      const currentRate = config.usageStats.successRate;
      config.usageStats.successRate = 
        (currentRate * (totalUsage - 1) + (success ? 1 : 0)) / totalUsage;
    }
  }

  /**
   * Obtient les mod√®les disponibles pour une famille donn√©e
   * Utilise la nouvelle configuration unifi√©e
   */
  getAvailableModelsByFamily(family: 'MT5' | 'NLLB'): TranslationModelType[] {
    return getModelsByFamily(family).map(config => config.name);
  }

  /**
   * Obtient tous les mod√®les disponibles
   */
  getAllAvailableModels(): TranslationModelType[] {
    return Object.keys(TRANSLATION_MODELS) as TranslationModelType[];
  }

  /**
   * V√©rifie si un mod√®le est disponible selon les capacit√©s syst√®me
   */
  isModelAvailable(modelType: TranslationModelType): boolean {
    const compatibleModels = getCompatibleModels(8192); // 8GB par d√©faut
    return compatibleModels.some(model => model.name === modelType);
  }

  /**
   * Recommande le meilleur mod√®le selon les crit√®res
   */
  recommendBestModel(options: {
    purpose: 'simple' | 'complex';
    priority: 'speed' | 'quality' | 'efficiency';
    maxMemoryMB?: number;
    family?: 'MT5' | 'NLLB';
  }): TranslationModelType {
    const recommended = recommendModel(options);
    return recommended.name;
  }

  /**
   * Obtient les m√©triques de performance d'un mod√®le
   */
  getModelMetrics(modelType: TranslationModelType): {
    config: ModelConfig;
    isLoaded: boolean;
    usageStats?: ModelConfig['usageStats'];
  } {
    const config = MODELS_CONFIG[modelType];
    const modelKey = this.getModelKey(modelType);
    
    return {
      config,
      isLoaded: this.isModelLoaded(modelKey),
      usageStats: config.usageStats
    };
  }

  /**
   * Traduit un texte avec un mod√®le sp√©cifique
   */
  async translateWithModel(
    text: string,
    sourceLanguage: string,
    targetLanguage: string,
    modelKey: string
  ): Promise<string> {
    try {
      // Charger le mod√®le si n√©cessaire
      const model = await this.loadModel(modelKey);
      
      if (!model) {
        // Fallback vers API externe si le mod√®le n'est pas disponible
        return this.translateWithFallback(text, sourceLanguage, targetLanguage, modelKey);
      }

      // Simulation de traduction avec TensorFlow.js
      // TODO: Impl√©menter la vraie inf√©rence TensorFlow.js
      const startTime = Date.now();
      
      // Pour l'instant, simulation avec un d√©lai r√©aliste
      const delay = Math.random() * 800 + 200; // 200-1000ms
      await new Promise(resolve => setTimeout(resolve, delay));
      
      const translatedText = `[${modelKey}] ${text} (${sourceLanguage} ‚Üí ${targetLanguage})`;
      
      // Mettre √† jour les statistiques
      const inferenceTime = Date.now() - startTime;
      const modelType = this.getModelType(modelKey);
      this.updateUsageStats(modelType, inferenceTime, true);
      
      return translatedText;
      
    } catch (error) {
      console.error(`‚ùå Erreur de traduction avec ${modelKey}:`, error);
      
      // Fallback vers API externe en cas d'erreur
      return this.translateWithFallback(text, sourceLanguage, targetLanguage, modelKey);
    }
  }

  /**
   * Traduit un texte en choisissant automatiquement le meilleur mod√®le
   */
  async translate(
    text: string,
    sourceLanguage: string,
    targetLanguage: string
  ): Promise<string> {
    try {
      // Recommander le meilleur mod√®le selon le texte
      const isComplex = text.length > 50 || /[,.;:!?(){}[\]"'`]/.test(text);
      const bestModel = recommendModel({
        purpose: isComplex ? 'complex' : 'simple',
        priority: 'efficiency',
        maxMemoryMB: 8192
      });

      const modelKey = this.getModelKey(bestModel.name);
      console.log(`ü§ñ Mod√®le recommand√©: ${bestModel.name} (${bestModel.displayName})`);
      
      return this.translateWithModel(text, sourceLanguage, targetLanguage, modelKey);
      
    } catch (error) {
      console.error('‚ùå Erreur de traduction automatique:', error);
      
      // Fallback ultime vers API externe
      return this.translateWithFallback(text, sourceLanguage, targetLanguage, 'fallback');
    }
  }

  /**
   * Traduction de fallback utilisant une API externe
   */
  private async translateWithFallback(
    text: string,
    sourceLanguage: string,
    targetLanguage: string,
    attemptedModel: string
  ): Promise<string> {
    try {
      console.log(`üåê Utilisation du fallback API pour: ${text} (${sourceLanguage} ‚Üí ${targetLanguage})`);
      
      // Utiliser MyMemory API comme fallback
      const url = new URL('https://api.mymemory.translated.net/get');
      url.searchParams.set('q', text);
      url.searchParams.set('langpair', `${sourceLanguage}|${targetLanguage}`);
      
      const response = await fetch(url.toString());
      
      if (!response.ok) {
        throw new Error(`API Error: ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.responseStatus === 200 && data.responseData?.translatedText) {
        console.log(`‚úÖ Traduction fallback r√©ussie: ${data.responseData.translatedText}`);
        return data.responseData.translatedText;
      } else {
        throw new Error('Invalid API response');
      }
      
    } catch (error) {
      console.error('‚ùå Erreur de traduction fallback:', error);
      
      // Derniers recours - traduction simul√©e
      console.log('üîÑ Utilisation de la traduction simul√©e comme dernier recours');
      return `[FALLBACK-${attemptedModel}] ${text} (${sourceLanguage} ‚Üí ${targetLanguage})`;
    }
  }
}

// Instance unique du gestionnaire de mod√®les
export const translationModels = new TranslationModels();

// Fonction utilitaire pour obtenir le co√ªt total d'une liste de traductions
export function calculateTranslationCost(translations: Array<{
  modelType: TranslationModelType;
  count: number;
}>): {
  totalEnergy: number;
  totalCO2: number;
  totalCost: number;
  totalTime: number;
} {
  return translations.reduce((acc, { modelType, count }) => {
    const config = MODELS_CONFIG[modelType];
    if (config) {
      acc.totalEnergy += config.cost.energyConsumption * count;
      acc.totalCO2 += config.cost.co2Equivalent * count;
      acc.totalCost += config.cost.monetaryEquivalent * count;
      acc.totalTime += config.cost.inferenceTime * count;
    }
    return acc;
  }, {
    totalEnergy: 0,
    totalCO2: 0,
    totalCost: 0,
    totalTime: 0
  });
}

export default translationModels;

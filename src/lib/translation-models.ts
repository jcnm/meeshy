import * as tf from '@tensorflow/tfjs';

// Types pour les mod√®les de traduction
export interface TranslationModel {
  name: string;
  maxTokens: number;
  complexity: 'simple' | 'complex';
  languages: string[];
}

// Configuration des mod√®les
export const MODELS_CONFIG: Record<string, TranslationModel> = {
  mt5: {
    name: 'MT5',
    maxTokens: 50,
    complexity: 'simple',
    languages: ['en', 'fr', 'es', 'de', 'it', 'pt', 'ru', 'ja', 'ko', 'zh']
  },
  nllb: {
    name: 'NLLB',
    maxTokens: 500,
    complexity: 'complex',
    languages: ['en', 'fr', 'es', 'de', 'it', 'pt', 'ru', 'ja', 'ko', 'zh', 'ar', 'hi', 'tr']
  }
};

// Service de gestion des mod√®les TensorFlow.js
export class TranslationModelsService {
  private static instance: TranslationModelsService;
  private models: Map<string, tf.GraphModel | null> = new Map();
  private loadingPromises: Map<string, Promise<tf.GraphModel>> = new Map();

  static getInstance(): TranslationModelsService {
    if (!TranslationModelsService.instance) {
      TranslationModelsService.instance = new TranslationModelsService();
    }
    return TranslationModelsService.instance;
  }

  private constructor() {
    // Initialiser les mod√®les comme null
    this.models.set('mt5', null);
    this.models.set('nllb', null);
  }

  /**
   * D√©termine quel mod√®le utiliser selon le message
   */
  selectModel(message: string): keyof typeof MODELS_CONFIG {
    const length = message.length;
    const hasComplexPunctuation = /[;:,!?(){}[\]"']/.test(message);
    const wordCount = message.split(/\s+/).length;

    // Utiliser MT5 pour les messages courts et simples
    if (length <= 50 && wordCount <= 10 && !hasComplexPunctuation) {
      return 'mt5';
    }

    // Utiliser NLLB pour les messages longs et complexes
    return 'nllb';
  }

  /**
   * Charge un mod√®le de traduction de mani√®re asynchrone
   */
  async loadModel(modelName: string): Promise<tf.GraphModel> {
    // Si le mod√®le est d√©j√† charg√©, le retourner
    const cachedModel = this.models.get(modelName);
    if (cachedModel) {
      return cachedModel;
    }

    // Si le mod√®le est en cours de chargement, attendre
    const loadingPromise = this.loadingPromises.get(modelName);
    if (loadingPromise) {
      return loadingPromise;
    }

    // Commencer le chargement du mod√®le
    const promise = this.loadModelFromPath(modelName);
    this.loadingPromises.set(modelName, promise);

    try {
      const model = await promise;
      this.models.set(modelName, model);
      this.loadingPromises.delete(modelName);
      console.log(`‚úÖ Mod√®le ${modelName} charg√© avec succ√®s`);
      return model;
    } catch (error) {
      this.loadingPromises.delete(modelName);
      console.error(`‚ùå Erreur lors du chargement du mod√®le ${modelName}:`, error);
      throw error;
    }
  }

  /**
   * Charge le mod√®le depuis le syst√®me de fichiers ou URL
   */
  private async loadModelFromPath(modelName: string): Promise<tf.GraphModel> {
    const modelPath = `/models/${modelName}/model.json`;
    
    try {
      // V√©rifier si le mod√®le existe
      const response = await fetch(modelPath, { method: 'HEAD' });
      if (!response.ok) {
        throw new Error(`Mod√®le ${modelName} non trouv√© √† ${modelPath}`);
      }

      // Charger le mod√®le TensorFlow.js
      const model = await tf.loadGraphModel(modelPath);
      return model;
    } catch (error) {
      console.warn(`‚ö†Ô∏è Mod√®le ${modelName} non disponible, utilisation du mock`);
      // Retourner un mod√®le factice pour le d√©veloppement
      return this.createMockModel();
    }
  }

  /**
   * Cr√©e un mod√®le factice pour le d√©veloppement
   */
  private createMockModel(): tf.GraphModel {
    // Cr√©er un mod√®le tr√®s simple pour les tests
    const model = {
      predict: () => tf.tensor2d([[0.8, 0.2]]),
      dispose: () => {},
      inputs: [],
      outputs: [],
      weights: [],
    } as unknown as tf.GraphModel;

    return model;
  }

  /**
   * Effectue une traduction avec le mod√®le appropri√©
   */
  async translate(
    text: string,
    sourceLang: string,
    targetLang: string
  ): Promise<string> {
    try {
      const modelName = this.selectModel(text);
      const model = await this.loadModel(modelName);

      // Pour le d√©veloppement, utiliser une traduction simul√©e
      if (!model || this.isMockModel(model)) {
        return this.simulateTranslation(text, sourceLang, targetLang, modelName);
      }

      // Ici, nous aurions la logique r√©elle de traduction avec TensorFlow.js
      // Pour l'instant, utiliser la simulation
      return this.simulateTranslation(text, sourceLang, targetLang, modelName);
    } catch (error) {
      console.error('Erreur lors de la traduction:', error);
      throw new Error(`Erreur de traduction: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * V√©rifie si c'est un mod√®le factice
   */
  private isMockModel(model: tf.GraphModel): boolean {
    return !model.inputs || model.inputs.length === 0;
  }

  /**
   * Simulation de traduction pour le d√©veloppement
   */
  private simulateTranslation(
    text: string,
    sourceLang: string,
    targetLang: string,
    modelUsed: string
  ): string {
    // Dictionnaire simple pour simulation
    const translations: Record<string, Record<string, string>> = {
      'Hello': { fr: 'Bonjour', es: 'Hola', de: 'Hallo', it: 'Ciao' },
      'How are you?': { fr: 'Comment allez-vous ?', es: '¬øC√≥mo est√°s?', de: 'Wie geht es dir?', it: 'Come stai?' },
      'Thank you': { fr: 'Merci', es: 'Gracias', de: 'Danke', it: 'Grazie' },
      'Good morning': { fr: 'Bonjour', es: 'Buenos d√≠as', de: 'Guten Morgen', it: 'Buongiorno' },
      'Goodbye': { fr: 'Au revoir', es: 'Adi√≥s', de: 'Auf Wiedersehen', it: 'Arrivederci' }
    };

    // Simulation bas√©e sur le texte exact ou traduction g√©n√©rique
    const exactTranslation = translations[text]?.[targetLang];
    if (exactTranslation) {
      return exactTranslation;
    }

    // Traduction g√©n√©rique avec indicateur du mod√®le utilis√©
    return `[${modelUsed.toUpperCase()}] ${text} ‚Üí ${targetLang}`;
  }

  /**
   * V√©rifie si un mod√®le est disponible
   */
  isModelLoaded(modelName: string): boolean {
    const model = this.models.get(modelName);
    return model !== null && model !== undefined;
  }

  /**
   * Lib√®re la m√©moire des mod√®les
   */
  dispose(): void {
    this.models.forEach((model, name) => {
      if (model) {
        model.dispose();
        console.log(`üóëÔ∏è Mod√®le ${name} lib√©r√© de la m√©moire`);
      }
    });
    this.models.clear();
    this.loadingPromises.clear();
  }

  /**
   * Obtient les informations sur l'√©tat des mod√®les
   */
  getModelsStatus(): Record<string, { loaded: boolean; loading: boolean }> {
    const status: Record<string, { loaded: boolean; loading: boolean }> = {};
    
    Object.keys(MODELS_CONFIG).forEach(modelName => {
      status[modelName] = {
        loaded: this.isModelLoaded(modelName),
        loading: this.loadingPromises.has(modelName)
      };
    });

    return status;
  }
}

// Instance singleton pour l'utilisation globale
export const translationModels = TranslationModelsService.getInstance();

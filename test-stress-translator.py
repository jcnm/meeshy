#!/usr/bin/env python3
"""
Script de test de stress pour le service de traduction Meeshy v0.4.7-alpha
√âvalue les performances avec les optimisations de logs et toasts
"""

import asyncio
import aiohttp
import time
import json
import statistics
from datetime import datetime
from typing import List, Dict
import psutil
import os

class TranslatorStressTest:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = []
        self.start_time = None
        self.end_time = None
        
    async def test_single_translation(self, session: aiohttp.ClientSession, text: str, 
                                    source_lang: str = "en", target_lang: str = "fr", 
                                    model_type: str = "basic") -> Dict:
        """Test une traduction individuelle"""
        payload = {
            "text": text,
            "source_language": source_lang,
            "target_language": target_lang,
            "model_type": model_type
        }
        
        start_time = time.time()
        try:
            async with session.post(f"{self.base_url}/translate", 
                                  json=payload, 
                                  timeout=aiohttp.ClientTimeout(total=30)) as response:
                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # en millisecondes
                
                if response.status == 200:
                    result = await response.json()
                    return {
                        "success": True,
                        "response_time": response_time,
                        "status_code": response.status,
                        "translated_text": result.get("translated_text", ""),
                        "confidence_score": result.get("confidence_score", 0),
                        "processing_time_ms": result.get("processing_time_ms", 0),
                        "model_used": result.get("model_used", "")
                    }
                else:
                    return {
                        "success": False,
                        "response_time": response_time,
                        "status_code": response.status,
                        "error": f"HTTP {response.status}"
                    }
        except Exception as e:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000
            return {
                "success": False,
                "response_time": response_time,
                "error": str(e)
            }
    
    async def test_concurrent_translations(self, num_requests: int, 
                                         concurrent_limit: int = 10) -> List[Dict]:
        """Test des traductions concurrentes"""
        print(f"üöÄ D√©marrage du test de stress: {num_requests} requ√™tes, {concurrent_limit} concurrentes")
        
        # Textes de test vari√©s
        test_texts = [
            "Hello world, this is a test message",
            "The quick brown fox jumps over the lazy dog",
            "Artificial intelligence is transforming the world",
            "Machine learning models are becoming more efficient",
            "Natural language processing enables better communication",
            "Translation services help bridge language barriers",
            "Technology continues to evolve rapidly",
            "Innovation drives progress in all fields",
            "Collaboration leads to better solutions",
            "Quality assurance ensures reliable results"
        ]
        
        semaphore = asyncio.Semaphore(concurrent_limit)
        
        async def limited_request(session, text, index):
            async with semaphore:
                return await self.test_single_translation(session, text)
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for i in range(num_requests):
                text = test_texts[i % len(test_texts)]
                task = limited_request(session, text, i)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Filtrer les exceptions
            valid_results = []
            for result in results:
                if isinstance(result, dict):
                    valid_results.append(result)
                else:
                    valid_results.append({
                        "success": False,
                        "response_time": 0,
                        "error": str(result)
                    })
            
            return valid_results
    
    def analyze_results(self, results: List[Dict]) -> Dict:
        """Analyse les r√©sultats du test"""
        successful_requests = [r for r in results if r.get("success", False)]
        failed_requests = [r for r in results if not r.get("success", False)]
        
        if not successful_requests:
            return {
                "total_requests": len(results),
                "successful_requests": 0,
                "failed_requests": len(failed_requests),
                "success_rate": 0,
                "error": "Aucune requ√™te r√©ussie"
            }
        
        response_times = [r["response_time"] for r in successful_requests]
        processing_times = [r.get("processing_time_ms", 0) for r in successful_requests]
        
        analysis = {
            "total_requests": len(results),
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": (len(successful_requests) / len(results)) * 100,
            "response_time_stats": {
                "mean": statistics.mean(response_times),
                "median": statistics.median(response_times),
                "min": min(response_times),
                "max": max(response_times),
                "std_dev": statistics.stdev(response_times) if len(response_times) > 1 else 0
            },
            "processing_time_stats": {
                "mean": statistics.mean(processing_times),
                "median": statistics.median(processing_times),
                "min": min(processing_times),
                "max": max(processing_times)
            },
            "requests_per_second": len(successful_requests) / (self.end_time - self.start_time),
            "errors": [r.get("error", "Unknown error") for r in failed_requests]
        }
        
        return analysis
    
    def get_system_stats(self) -> Dict:
        """R√©cup√®re les statistiques syst√®me"""
        process = psutil.Process()
        return {
            "cpu_percent": process.cpu_percent(),
            "memory_mb": process.memory_info().rss / 1024 / 1024,
            "system_cpu_percent": psutil.cpu_percent(),
            "system_memory_percent": psutil.virtual_memory().percent
        }
    
    async def run_stress_test(self, num_requests: int = 100, concurrent_limit: int = 10):
        """Ex√©cute le test de stress complet"""
        print("=" * 80)
        print("üß™ TEST DE STRESS - Meeshy Translator v0.4.7-alpha")
        print("=" * 80)
        print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üéØ Objectif: {num_requests} requ√™tes, {concurrent_limit} concurrentes")
        print()
        
        # Statistiques syst√®me avant le test
        print("üìä Statistiques syst√®me avant le test:")
        initial_stats = self.get_system_stats()
        print(f"   CPU: {initial_stats['cpu_percent']:.1f}%")
        print(f"   M√©moire: {initial_stats['memory_mb']:.1f} MB")
        print(f"   CPU syst√®me: {initial_stats['system_cpu_percent']:.1f}%")
        print(f"   M√©moire syst√®me: {initial_stats['system_memory_percent']:.1f}%")
        print()
        
        # Test de sant√© avant le stress
        print("üè• Test de sant√© du service...")
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/health", timeout=5) as response:
                    if response.status == 200:
                        print("‚úÖ Service en bonne sant√©")
                    else:
                        print(f"‚ö†Ô∏è Service r√©pond mais statut: {response.status}")
        except Exception as e:
            print(f"‚ùå Erreur de sant√©: {e}")
            return
        
        print()
        print("üöÄ D√©marrage du test de stress...")
        
        self.start_time = time.time()
        results = await self.test_concurrent_translations(num_requests, concurrent_limit)
        self.end_time = time.time()
        
        # Statistiques syst√®me apr√®s le test
        final_stats = self.get_system_stats()
        
        # Analyse des r√©sultats
        analysis = self.analyze_results(results)
        
        # Affichage des r√©sultats
        print()
        print("=" * 80)
        print("üìà R√âSULTATS DU TEST DE STRESS")
        print("=" * 80)
        
        print(f"üìä R√©sum√© g√©n√©ral:")
        print(f"   Total des requ√™tes: {analysis['total_requests']}")
        print(f"   Requ√™tes r√©ussies: {analysis['successful_requests']}")
        print(f"   Requ√™tes √©chou√©es: {analysis['failed_requests']}")
        print(f"   Taux de succ√®s: {analysis['success_rate']:.1f}%")
        print(f"   Requ√™tes par seconde: {analysis['requests_per_second']:.1f}")
        
        print()
        print(f"‚è±Ô∏è Temps de r√©ponse (ms):")
        rt_stats = analysis['response_time_stats']
        print(f"   Moyenne: {rt_stats['mean']:.1f}")
        print(f"   M√©diane: {rt_stats['median']:.1f}")
        print(f"   Min: {rt_stats['min']:.1f}")
        print(f"   Max: {rt_stats['max']:.1f}")
        print(f"   √âcart-type: {rt_stats['std_dev']:.1f}")
        
        print()
        print(f"‚öôÔ∏è Temps de traitement ML (ms):")
        pt_stats = analysis['processing_time_stats']
        print(f"   Moyenne: {pt_stats['mean']:.1f}")
        print(f"   M√©diane: {pt_stats['median']:.1f}")
        print(f"   Min: {pt_stats['min']:.1f}")
        print(f"   Max: {pt_stats['max']:.1f}")
        
        print()
        print(f"üíª Utilisation syst√®me:")
        print(f"   CPU avant: {initial_stats['cpu_percent']:.1f}% ‚Üí apr√®s: {final_stats['cpu_percent']:.1f}%")
        print(f"   M√©moire avant: {initial_stats['memory_mb']:.1f} MB ‚Üí apr√®s: {final_stats['memory_mb']:.1f} MB")
        print(f"   CPU syst√®me: {initial_stats['system_cpu_percent']:.1f}% ‚Üí {final_stats['system_cpu_percent']:.1f}%")
        print(f"   M√©moire syst√®me: {initial_stats['system_memory_percent']:.1f}% ‚Üí {final_stats['system_memory_percent']:.1f}%")
        
        if analysis['errors']:
            print()
            print(f"‚ùå Erreurs rencontr√©es:")
            error_counts = {}
            for error in analysis['errors']:
                error_counts[error] = error_counts.get(error, 0) + 1
            for error, count in error_counts.items():
                print(f"   {error}: {count} fois")
        
        print()
        print("=" * 80)
        print("üéØ √âVALUATION DES PERFORMANCES")
        print("=" * 80)
        
        # √âvaluation des performances
        if analysis['success_rate'] >= 95:
            print("‚úÖ Excellent: Taux de succ√®s tr√®s √©lev√©")
        elif analysis['success_rate'] >= 90:
            print("‚úÖ Bon: Taux de succ√®s √©lev√©")
        elif analysis['success_rate'] >= 80:
            print("‚ö†Ô∏è Acceptable: Taux de succ√®s correct")
        else:
            print("‚ùå Probl√©matique: Taux de succ√®s faible")
        
        if rt_stats['mean'] < 1000:
            print("‚úÖ Excellent: Temps de r√©ponse tr√®s rapide")
        elif rt_stats['mean'] < 2000:
            print("‚úÖ Bon: Temps de r√©ponse rapide")
        elif rt_stats['mean'] < 5000:
            print("‚ö†Ô∏è Acceptable: Temps de r√©ponse correct")
        else:
            print("‚ùå Probl√©matique: Temps de r√©ponse lent")
        
        if analysis['requests_per_second'] > 10:
            print("‚úÖ Excellent: D√©bit √©lev√©")
        elif analysis['requests_per_second'] > 5:
            print("‚úÖ Bon: D√©bit correct")
        elif analysis['requests_per_second'] > 2:
            print("‚ö†Ô∏è Acceptable: D√©bit mod√©r√©")
        else:
            print("‚ùå Probl√©matique: D√©bit faible")
        
        print()
        print("üèÅ Test de stress termin√©!")

async def main():
    """Fonction principale"""
    test = TranslatorStressTest()
    
    # Tests avec diff√©rentes charges
    test_scenarios = [
        {"requests": 50, "concurrent": 5, "name": "Test l√©ger"},
        {"requests": 100, "concurrent": 10, "name": "Test moyen"},
        {"requests": 200, "concurrent": 20, "name": "Test intensif"}
    ]
    
    for scenario in test_scenarios:
        print(f"\n{'='*20} {scenario['name']} {'='*20}")
        await test.run_stress_test(scenario['requests'], scenario['concurrent'])
        await asyncio.sleep(5)  # Pause entre les tests

if __name__ == "__main__":
    asyncio.run(main())
